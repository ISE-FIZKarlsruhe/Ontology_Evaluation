{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-e49bYW241gI"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade git+https://github.com/UKPLab/sentence-transformers\n",
    "!pip install keybert ctransformers[cuda]\n",
    "!pip install --upgrade git+https://github.com/huggingface/transformers\n",
    "!pip install spacy\n",
    "!pip install yake\n",
    "!pip install gensim\n",
    "!pip install pyate\n",
    "!pip install rake-nltk\n",
    "!pip install summa\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install keybert\n",
    "!pip install huggingface_hu==0.10.1\n",
    "!pip install bibtexparser\n",
    "!pip install Levenshtein\n",
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EnGxC3El6QSq"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from ctransformers import AutoModelForCausalLM as CAutoModelForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from keybert.llm import TextGeneration\n",
    "from keybert import KeyLLM, KeyBERT\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eIE_nf2opzMg",
    "outputId": "bc305a81-078f-4cd8-ed58-0d1db710ba13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ebrahim/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1yoTEmSUROI-"
   },
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "from yake import KeywordExtractor\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from yake import KeywordExtractor\n",
    "from rake_nltk import Rake\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "from pyate import combo_basic, basic, cvalues\n",
    "from summa import keywords as summa_keywords\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from keybert import KeyBERT\n",
    "from nltk.stem import PorterStemmer\n",
    "from Levenshtein import distance\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0-W92b0sRQUS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ebrahim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mZRPR0ecBKDq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f19aab4a8342e7adf35d805df5b7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193fcf8afa534baaabc9e90dd6fdcd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_cuda_set_main_device: using device 0 (NVIDIA A100 80GB PCIe) as main device\n"
     ]
    }
   ],
   "source": [
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "model_mistral = CAutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=50,\n",
    "    hf=True\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer_mistral = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Pipeline\n",
    "generator_mistral = pipeline(\n",
    "    model=model_mistral, tokenizer=tokenizer_mistral,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=50,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fdae5f795d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load(\"en_core_web_lg\")\n",
    "spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87de0e4fd0a4d1bb8b2e56deb090d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "model_mixtral = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer_mixtral = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "generator_mixtral = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_mixtral, tokenizer=tokenizer_mixtral, max_new_tokens=100,\n",
    "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_4bit\": True},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"\"\"\n",
    "<s>[INST]\n",
    "I have the following document:\n",
    "- Localized magnetic hyperthermia using magnetic nanoparticles (MNPs) under the application of small magnetic fields is a promising tool for treating small or deep-seated tumors.\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST] localized magnetic hyperthermia,magnetic nanoparticles (MNPs),magnetic fields</s>\"\"\"\n",
    "\n",
    "keyword_prompt = \"\"\"\n",
    "[INST]\n",
    "\n",
    "I have the following document:\n",
    "- [DOCUMENT]\n",
    "\n",
    "Please give me the keywords that are present in this document and separate them with commas.\n",
    "Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
    "\"Here are the keywords present in the document\"\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = example_prompt + keyword_prompt\n",
    "\n",
    "# Mistral7B\n",
    "llm_mistral = TextGeneration(generator_mistral, prompt=prompt)\n",
    "llm_mixtral = TextGeneration(generator_mixtral, prompt=prompt)\n",
    "\n",
    "#kw_model = KeyLLM(llm)\n",
    "#Mistral7B_keywords = kw_model.extract_keywords([abstract])[0]\n",
    "\n",
    "# Mistral7B_embeddings\n",
    "#model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
    "#embeddings = model.encode([abstract], convert_to_tensor=True)\n",
    "#Mistral7B_embeddings_keywords = kw_model.extract_keywords([abstract], embeddings=embeddings, threshold=.5)[0]\n",
    "\n",
    "# Mistral7B_KeyBERT\n",
    "kw_model_mistral = KeyBERT(llm=llm_mistral, model='BAAI/bge-small-en-v1.5')\n",
    "kw_model_mixtral = KeyBERT(llm=llm_mixtral, model='BAAI/bge-small-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PlOgU86TRT05"
   },
   "outputs": [],
   "source": [
    "def extract_keywords_from_abstract(abstract):\n",
    "\n",
    "    # Mistral7B\n",
    "    Mistral7B_KeyBERT_keywords = kw_model_mistral.extract_keywords([abstract], threshold=.5)[0]\n",
    "    Mixtral7B_KeyBERT_keywords = kw_model_mixtral.extract_keywords([abstract], threshold=.5)[0]\n",
    "\n",
    "    # Get the English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    abstract = ' '.join([word for word in abstract.split() if word.lower() not in stop_words])\n",
    "\n",
    "    # Initialize Spacy, YAKE, and RAKE keyword extractors\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    kw_extractor = KeywordExtractor() # KeywordExtractor(lan=\"en\", n=3, dedupLim=0.6, dedupFunc='seqm', windowsSize=1, top=20, features=None)\n",
    "    rake_nltk_var = Rake()\n",
    "\n",
    "    # Extract keywords using Spacy entities\n",
    "    doc = nlp(abstract)\n",
    "    spacy_entities = [ent.text for ent in doc.ents]\n",
    "\n",
    "    # Extract keywords using Spacy noun chunks\n",
    "    doc = nlp(abstract)\n",
    "    spacy_noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "    # Extract keywords using YAKE\n",
    "    yake_keywords = kw_extractor.extract_keywords(abstract)\n",
    "    yake_keywords = [keyword[0] for keyword in yake_keywords]\n",
    "\n",
    "    # Extract keywords using RAKE\n",
    "    rake_nltk_var.extract_keywords_from_text(abstract)\n",
    "    rake_keywords = rake_nltk_var.get_ranked_phrases()\n",
    "\n",
    "    # Extract keywords using Pyate\n",
    "    pyate_combo_basic_keywords = combo_basic(abstract).sort_values(ascending=False).index.str.split().str[0].tolist()\n",
    "    pyate_basic_keywords = basic(abstract).sort_values(ascending=False).index.str.split().str[0].tolist()\n",
    "    pyate_cvalues_keywords = cvalues(abstract).sort_values(ascending=False).index.str.split().str[0].tolist()\n",
    "\n",
    "    # Extract keywords using summa\n",
    "    summa_keywords_ = [keyword[0] for keyword in summa_keywords.keywords(abstract, scores=True)]\n",
    "    \n",
    "    # Extract keywords using KeyBERT\n",
    "    keybert_model = KeyBERT()#KeyBERT(model=\"m3rg-iitd/matscibert\")#KeyBERT()\n",
    "    keybert_keywords = [keyword[0] for keyword in keybert_model.extract_keywords(abstract, keyphrase_ngram_range=(1, 3), stop_words='english')] #keyphrase_ngram_range=(1, 3),\n",
    "    \n",
    "    # Extract keywords using KeyBERT+MatSciBERT\n",
    "    keybert_m_model = KeyBERT(model=\"m3rg-iitd/matscibert\")#KeyBERT()\n",
    "    keybert_m_keywords = [keyword[0] for keyword in keybert_m_model.extract_keywords(abstract, keyphrase_ngram_range=(1, 3), stop_words='english')] #keyphrase_ngram_range=(1, 3),\n",
    "\n",
    "    # Extract keywords using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([abstract])\n",
    "    tfidf_keywords = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Extract keywords using LSA\n",
    "    lsa_model = TruncatedSVD(n_components=10)  # Adjust the number of components as needed\n",
    "    lsa_matrix = lsa_model.fit_transform(tfidf_matrix)\n",
    "    lsa_keywords = [tfidf_keywords[i] for i in lsa_model.components_[0].argsort()[::-1]]\n",
    "\n",
    "    # Extract keywords using LDA\n",
    "    dictionary = Dictionary([abstract.split()])\n",
    "    corpus = [dictionary.doc2bow(abstract.split())]\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in [abstract.split()]]\n",
    "    lda_model = LdaModel(corpus=doc_term_matrix, num_topics=10, id2word=dictionary)  # Adjust the number of topics as needed\n",
    "    lda_keywords = [word for word, _ in lda_model.show_topic(0)]\n",
    "\n",
    "    return {\n",
    "        \"Spacy_entities\": spacy_entities,\n",
    "        \"Spacy_noun_chunks\": spacy_noun_chunks,\n",
    "        \"YAKE_keywords\": yake_keywords,\n",
    "        \"RAKE_keywords\": rake_keywords,\n",
    "        \"Pyate_combo_basic_keywords\": pyate_combo_basic_keywords,\n",
    "        \"Pyate_basic_keywords\": pyate_basic_keywords,\n",
    "        \"Pyate_cvalues_keywords\": pyate_cvalues_keywords,\n",
    "        \"Summa_keywords\": summa_keywords_,\n",
    "        \"Keybert_keywords\": keybert_keywords,\n",
    "        \"Keybert_m_keywords\": keybert_m_keywords,\n",
    "        \"TFIDF_keywords\": tfidf_keywords,\n",
    "        \"LSA_keywords\": lsa_keywords,\n",
    "        \"LDA_keywords\": lda_keywords,\n",
    "        #\"Mistral7B\": Mistral7B_keywords,\n",
    "        #\"Mistral7B_embeddings\": Mistral7B_embeddings_keywords,\n",
    "        \"Mistral7B_KeyBERT\": Mistral7B_KeyBERT_keywords,\n",
    "        \"Mixtral7B_KeyBERT\": Mixtral7B_KeyBERT_keywords,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jEURTGyoR6K9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy_entities:  []\n",
      "Spacy_noun_chunks:  ['Functionalization', 'targeted delivery nanoparticles', 'various cell types', 'bioimaging', 'gene delivery', 'drug delivery therapeutic diagnostic applications']\n",
      "YAKE_keywords:  ['therapeutic diagnostic applications', 'Functionalization facilitates targeted', 'drug delivery therapeutic', 'facilitates targeted delivery', 'targeted delivery nanoparticles', 'delivery therapeutic diagnostic', 'Functionalization facilitates', 'cell types', 'diagnostic applications', 'facilitates targeted', 'nanoparticles various cell', 'therapeutic diagnostic', 'gene delivery', 'drug delivery', 'targeted delivery', 'delivery nanoparticles', 'delivery therapeutic', 'bioimaging', 'delivery', 'Functionalization']\n",
      "RAKE_keywords:  ['functionalization facilitates targeted delivery nanoparticles various cell types', 'drug delivery therapeutic diagnostic applications', 'gene delivery', 'bioimaging']\n",
      "Pyate_combo_basic_keywords:  ['delivery', 'therapeutic', 'drug', 'diagnostic', 'therapeutic', 'delivery', 'delivery', 'drug', 'drug', 'drug', 'various', 'cell', 'various', 'functionalization', 'gene']\n",
      "Pyate_basic_keywords:  ['delivery', 'therapeutic', 'drug', 'diagnostic', 'delivery', 'therapeutic', 'drug', 'delivery', 'various', 'cell', 'drug', 'drug', 'various', 'functionalization', 'gene']\n",
      "Pyate_cvalues_keywords:  ['drug', 'delivery', 'various', 'therapeutic', 'functionalization', 'various', 'cell', 'gene', 'drug', 'diagnostic', 'drug', 'drug', 'delivery', 'delivery', 'therapeutic']\n",
      "Summa_keywords:  ['delivery', 'types']\n",
      "Keybert_keywords:  ['targeted delivery nanoparticles', 'delivery nanoparticles', 'delivery nanoparticles various', 'drug delivery therapeutic', 'delivery therapeutic']\n",
      "Keybert_m_keywords:  ['gene delivery drug', 'drug delivery therapeutic', 'drug delivery', 'targeted delivery nanoparticles', 'delivery drug']\n",
      "TFIDF_keywords:  ['applications' 'bioimaging' 'bioimaging gene' 'bioimaging gene delivery'\n",
      " 'cell' 'cell types' 'cell types bioimaging' 'delivery' 'delivery drug'\n",
      " 'delivery drug delivery' 'delivery nanoparticles'\n",
      " 'delivery nanoparticles various' 'delivery therapeutic'\n",
      " 'delivery therapeutic diagnostic' 'diagnostic' 'diagnostic applications'\n",
      " 'drug' 'drug delivery' 'drug delivery therapeutic' 'facilitates'\n",
      " 'facilitates targeted' 'facilitates targeted delivery'\n",
      " 'functionalization' 'functionalization facilitates'\n",
      " 'functionalization facilitates targeted' 'gene' 'gene delivery'\n",
      " 'gene delivery drug' 'nanoparticles' 'nanoparticles various'\n",
      " 'nanoparticles various cell' 'targeted' 'targeted delivery'\n",
      " 'targeted delivery nanoparticles' 'therapeutic' 'therapeutic diagnostic'\n",
      " 'therapeutic diagnostic applications' 'types' 'types bioimaging'\n",
      " 'types bioimaging gene' 'various' 'various cell' 'various cell types']\n",
      "LSA_keywords:  ['delivery', 'various cell types', 'delivery nanoparticles', 'drug delivery therapeutic', 'drug delivery', 'drug', 'diagnostic applications', 'diagnostic', 'delivery therapeutic diagnostic', 'delivery therapeutic', 'delivery nanoparticles various', 'delivery drug delivery', 'facilitates targeted', 'delivery drug', 'cell types bioimaging', 'cell types', 'cell', 'bioimaging gene delivery', 'bioimaging gene', 'bioimaging', 'facilitates', 'facilitates targeted delivery', 'various cell', 'targeted delivery', 'various', 'types bioimaging gene', 'types bioimaging', 'types', 'therapeutic diagnostic applications', 'therapeutic diagnostic', 'therapeutic', 'targeted delivery nanoparticles', 'targeted', 'functionalization', 'nanoparticles various cell', 'nanoparticles various', 'nanoparticles', 'gene delivery drug', 'gene delivery', 'gene', 'functionalization facilitates targeted', 'functionalization facilitates', 'applications']\n",
      "LDA_keywords:  ['delivery', 'facilitates', 'targeted', 'Functionalization', 'delivery,', 'therapeutic', 'diagnostic', 'cell', 'applications.', 'various']\n",
      "Mistral7B_KeyBERT:  ['functionalization', 'nanoparticles', 'targeted delivery', 'cell types', 'bioimaging', 'gene delivery', 'drug delivery', 'therapeutic applications', 'diagnostic applications.']\n",
      "Mixtral7B_KeyBERT:  ['functionalization', 'targeted delivery', 'nanoparticles', 'cell types', 'bioimaging', 'gene delivery', 'drug delivery', 'therapeutic applications', 'diagnostic applications.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "abstract = \"Functionalization facilitates targeted delivery of these nanoparticles to various cell types, bioimaging, gene delivery, drug delivery and other therapeutic and diagnostic applications.\"\n",
    "keywords = extract_keywords_from_abstract(abstract)\n",
    "for method, extracted_keywords in keywords.items():\n",
    "    print(method + \": \", extracted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "z5yPhE-VR73U"
   },
   "outputs": [],
   "source": [
    "# Function to tokenize and stem text\n",
    "def tokenize_and_stem(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    if isinstance(text, str):\n",
    "        tokens = [stemmer.stem(word) for word in text.split()]\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return str(text)\n",
    "\n",
    "# Function to calculate Levenshtein distance similarity\n",
    "def levenshtein_similarity(text1, text2):\n",
    "    return 1 - (distance(text1, text2) / max(len(text1), len(text2)))\n",
    "\n",
    "# Function to find synonyms using WordNet\n",
    "def find_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "# Function to calculate cosine similarity using TF-IDF\n",
    "def cosine_similarity_score(text1, text2):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split())\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    return cosine_similarity(tfidf_matrix)[0][1]\n",
    "\n",
    "# Function to calculate fuzzy matching score\n",
    "def fuzzy_matching_score(text1, text2):\n",
    "    return fuzz.token_set_ratio(text1, text2)\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "\n",
    "# Function to evaluate keywords with Levenshtein threshold\n",
    "def evaluate_keywords(ground_truth_keywords, extracted_keywords, threshold=0.8):\n",
    "    ground_truth_keywords = list(set(ground_truth_keywords))\n",
    "    extracted_keywords = list(set(extracted_keywords))\n",
    "    \n",
    "    # Initialize variables for evaluation metrics\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "\n",
    "    # Tokenize and stem ground truth keywords\n",
    "    ground_truth_stems = [tokenize_and_stem(keyword) for keyword in ground_truth_keywords]\n",
    "\n",
    "    # Iterate over extracted keywords\n",
    "    for extracted_keyword in extracted_keywords:\n",
    "        # Tokenize and stem extracted keyword\n",
    "        extracted_stem = tokenize_and_stem(extracted_keyword)\n",
    "\n",
    "        # Check if extracted keyword matches any ground truth keyword within Levenshtein threshold\n",
    "        matched = False\n",
    "        for ground_truth_stem in ground_truth_stems:\n",
    "            max_len = max(len(extracted_stem), len(ground_truth_stem))\n",
    "            if Levenshtein.distance(extracted_stem, ground_truth_stem) / max_len <= 1 - threshold:\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        # Update evaluation metrics based on match status\n",
    "        if matched:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    # Calculate false negatives (missed ground truth keywords)\n",
    "    fn = len(ground_truth_keywords) - tp\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "\n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = 0.0\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BQftyxNhSBA7"
   },
   "outputs": [],
   "source": [
    "def evaluate_keywords_from_bib(bib_file, extraction_functions, output_folder):\n",
    "    # Load the BibTeX file\n",
    "    with open(bib_file, 'r', encoding='utf-8') as bibfile:\n",
    "        bib_database = bibtexparser.load(bibfile)\n",
    "\n",
    "    # Initialize dictionaries to store cumulative scores\n",
    "    cumulative_precision = {method: 0 for method in extraction_functions}\n",
    "    cumulative_recall = {method: 0 for method in extraction_functions}\n",
    "    cumulative_f1_score = {method: 0 for method in extraction_functions}\n",
    "    total_abstracts = 0\n",
    "\n",
    "    # Initialize lists to store ground truth keywords, extracted keywords, and evaluation results\n",
    "    all_extracted_keywords = []\n",
    "    all_evaluation_results = []\n",
    "    all_evaluation_results_avg = []\n",
    "\n",
    "    # Iterate over entries in the BibTeX file\n",
    "    for entry in bib_database.entries:\n",
    "        # Check if the entry has abstract and keywords\n",
    "        if 'abstract' in entry and 'keywords' in entry:\n",
    "            abstract = entry['abstract'].lower()\n",
    "            ground_truth_keywords = entry['keywords'].split(',')\n",
    "            total_abstracts += 1\n",
    "\n",
    "            # Evaluate keywords for each extraction function\n",
    "            for method, extraction_function in extraction_functions.items():\n",
    "                extracted_keywords = extraction_function(abstract)\n",
    "                precision, recall, f1_score = evaluate_keywords(ground_truth_keywords, extracted_keywords)\n",
    "\n",
    "                # Accumulate scores\n",
    "                cumulative_precision[method] += precision\n",
    "                cumulative_recall[method] += recall\n",
    "                cumulative_f1_score[method] += f1_score\n",
    "\n",
    "                # Append data for CSV output\n",
    "                all_evaluation_results.append((ground_truth_keywords, extracted_keywords, method, precision, recall, f1_score))\n",
    "\n",
    "    # Calculate averages\n",
    "    average_precision = {method: cumulative_precision[method] / total_abstracts for method in extraction_functions}\n",
    "    average_recall = {method: cumulative_recall[method] / total_abstracts for method in extraction_functions}\n",
    "    average_f1_score = {method: cumulative_f1_score[method] / total_abstracts for method in extraction_functions}\n",
    "\n",
    "    # Print average scores\n",
    "    print(\"Average Scores over all Abstracts:\")\n",
    "    for method in extraction_functions:\n",
    "        print(f\"Method      , Average Precision:                    , Average Recall:                    , Average F1-score:                    \")\n",
    "        print(f\"{method},{average_precision[method]},{average_recall[method]},{average_f1_score[method]}\")\n",
    "        all_evaluation_results_avg.append((method, average_precision[method], average_recall[method], average_f1_score[method]))\n",
    "\n",
    "    # Write ground truth keywords, extracted keywords, and evaluation results to CSV files\n",
    "    with open(os.path.join(output_folder, 'evaluation_results.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Ground_truth Keywords', 'Extracted Keywords', 'Method', 'Precision', 'Recall', 'F1-score'])\n",
    "        writer.writerows(all_evaluation_results)\n",
    "    \n",
    "    with open(os.path.join(output_folder, 'evaluation_results_avg.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Method', 'Precision', 'Recall', 'F1-score'])\n",
    "        writer.writerows(all_evaluation_results_avg)\n",
    "\n",
    "# Define extraction functions\n",
    "extraction_functions = {\n",
    "    \"Spacy_entities\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Spacy_entities\"],\n",
    "    \"Spacy_noun_chunks\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Spacy_noun_chunks\"],\n",
    "    \"YAKE_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"YAKE_keywords\"],\n",
    "    \"RAKE_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"RAKE_keywords\"],\n",
    "    \"Pyate_combo_basic_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Pyate_combo_basic_keywords\"],\n",
    "    \"Pyate_basic_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Pyate_basic_keywords\"],\n",
    "    \"Pyate_cvalues_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Pyate_cvalues_keywords\"],\n",
    "    \"Summa_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Summa_keywords\"],\n",
    "    \"Keybert_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Keybert_keywords\"],\n",
    "    \"Keybert_m_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Keybert_m_keywords\"],\n",
    "    \"TFIDF_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"TFIDF_keywords\"],\n",
    "    \"LSA_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"LSA_keywords\"],\n",
    "    \"LDA_keywords\": lambda abstract: extract_keywords_from_abstract(abstract)[\"LDA_keywords\"],\n",
    "    #\"Mistral7B\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mistral7B\"],\n",
    "    #\"Mistral7B_embeddings\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mistral7B_embeddings\"],\n",
    "    \"Mistral7B_KeyBERT\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mistral7B_KeyBERT\"],\n",
    "    \"Mixtral7B_KeyBERT\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mixtral7B_KeyBERT\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8u-D9D_OSDA8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "No sentence-transformers model found with name m3rg-iitd/matscibert. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ebrahim/.local/lib/python3.10/site-packages/sklearn/decomposition/_truncated_svd.py:273: RuntimeWarning: invalid value encountered in divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "bib_file = \"nanomaterials-v01-i01_20240418_texts/nanomaterials-v01-i01_20240418.bib\"\n",
    "\n",
    "# Specify the output folder\n",
    "output_folder = \"Results_llm/\"\n",
    "\n",
    "evaluate_keywords_from_bib(bib_file, extraction_functions, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "372ad118f81acd4222add26895f13bc27a937b9d5021100e967f342fe93795e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
