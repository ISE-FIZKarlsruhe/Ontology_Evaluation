Machine learning is the discipline of learning commands in the computer machine to predict and expect the results of real application and is currently the most promising simulation in artificial intelligence. This paper aims at using different algorithms to calculate and predict the compressive strength of extrusion 3DP concrete (cement mortar). The investigation is carried out using multi-objective grasshopper optimization algorithm (MOGOA) and artificial neural network (ANN). Given that the accuracy of a machine learning method depends on the number of data records, and for concrete 3D printing, this number is limited to few years of study, this work develops a new method by combining both methodologies into an ANNMOGOA approach to predict the compressive strength of 3D-printed concrete. Some promising results in the iteration process are achieved.
Extrusion 3DP is known as one of the most promising techniques for the con-struction industry. Therefore, it is also referred to as “number one 3DP technology in Additive Manufacturing (AM) for construction” [
1
,
2
]. AM is a digital manufacturing technique to produce 3D printed parts and works based on a layer by layer printing which is supported by CAD files. This technique could help to construct complicated geometries which are hard to fabricate by formwork. In recent years, AM techniques endeavour to produce great structural members which can be suitable to build on Earth and beyond planet Earth.
Although there are many studies on predicting concrete mechanical strength for conventional concrete casting, there is not any convenient study or only a few on ma-chine learning (ML) for 3D printing concrete. For example, Dutta, et al. [
3
] used 1200 dataset samples for the evaluation of the concrete compressive strength of mix designs with coarse aggregates smaller than 20 mm. In their study, they have developed three models and they have selected the best suited model which can be applicable to use in predicting the compressive strength. According to their investigation, the cement con-tent in the concrete matrix has a major influence on the concrete compressive strength.
ML is another tool of digital transformation in the 21st century ML allows the computer to learn automatically from the entry data and make the decision and pre-dictions without having been specifically programmed [
4
].
Having ML technology with a large number of collected data would be beneficial to use as an Artificial Intelligence (AI) to prove the quality of production and predicting mechanical strength. [
5
]. It is vital to address that the data alone cannot provide enough information without having it analysed and interpreted correctly [
6
].
According to an earlier study by Obermeyer and Emanuel [
6
], AI includes three main AM applications, namely Powder-Bed Fusion, Directed Energy Deposition and Material Extrusion. However, it can be stated that all types of AM could be part of AI as long as sufficient information and data on them is available [
7
].
According to the study of Meng, et al. [
8
], all types of neural networks refer to ar-tificial neural networks (ANN). Usually, a neural network (NN) comprises an input layer which is usually one or more hidden layers and one or more output layers. The layer is created of numerous neurons and the data of each neuron is spread to the next layer based on different weights. In ANN, categorized under regular NN, the spreading neurons form as a cycle and are fed through NN. Moreover, while it is under training condition, each neuron’s weight would be optimized by the learning instruction and new information is imported into the NN. The most popular learning rule for NN is the Back-Propagation (BP) algorithm [
9
,
10
] which controls weight based on the gradient descent.
Zhang, et al. [
11
] used NN in the AM process to predict the tensile strength for the printed part, the RMSE value recorded only 2%. 
Figure 1
 describes the NN which was performed made during training when the output of each input is spreading backward in the NN to adjust the relevance of each input feature. After training, a new combina-tion of input features is spreading forward to guess the tensile strength value. Generally, NN displayed excellent performance in regression tasks, but it still requires to have some essential tuning of some hyperparameters, such as the number of hidden neurons and layers. Therefore, in this paper, a multi-objective optimization algorithm is used to find the optimal structure of the ANN for predicting compressive strength of 3DP concrete.
The present study investigates and interprets the use of ML to be suitable for the AM-based process in 3D printing concrete/mortar applications. The study has collected data from 26 studies that have mentioned a mixed proportion of cementitious materials properly. In particular, the paper discusses the best-suited algorithm method for pre-dicting the mechanical strength of 3DP concrete, among which the most suited method in ML is selected. Then, literature studies are gathered in the mix design and are in-tensely used as input to predict the mechanical strength of concrete.
The research’s methodological approach is discussed in this section. The method-ology of ANN is presented after introducing the GOA and MOGOA. Afterwards, a model is proposed which is a mix of ANN and MOGOA.
Grasshoppers are a species of insects that live in large hordes, despite being ob-served individually [
12
]. Their swarming activity begins while they are nymphs and continues throughout maturity [
13
]. Nymph grasshoppers migrate by hopping and leaping in a cylinder-like pattern [
14
]. Their colony travels slowly and in little incre-ments throughout this period. Therefore, the grasshopper’s algorithm is based on the nature of the grasshopper’s life exploration. This algorithm, like some other evolution algorithms, begins with inquiry and ends with exploitation. Whilst agents seek in the distance during the discovery phase, they explore the nearest region during the ex-ploitation phase. The following is the Equation (1) that models of grasshopper swarming attitudes:










P


i




=




x


2








Fg




i




+




x


1






S


i




+




x


3








Aw




i




,










(1)





where Aw
i
 and 








Fg




i






 represent wind advection and force of gravity on the grasshopper in position i, S
i
 indicates social contact as indicated in Equation (2), P
i
 represents the ith search agent’s position, and x
1
, x
2
, and x
3
 are values that are chosen randomly in [0, 1] to provide random behaviour.











S


i




=






∑














k


=


1














k


≠


i












N




s


 


(




d


ik




)


 








d




ik








^












(2)




Here, the distance between both the ith and jth grasshopper is 






d




ik








, which is calculated by Equation (3); 










d




ik








^






 is just the unit vector again from ith towards jth grasshopper, as obtained by Equation (4), where s is indeed a function to characterize the intensity of the social forces, as calculated by Equation (5).











d




ij






=




|






p


j




−




p


i






|




;










(3)


















d




ij








^




=








p


j




−




p


i










d




ij










;










(4)












s




(


l


)




=






be










−


l




m








−




e




−


l






,










(5)





where m stands for the appealing length scale and b indicates attractive intensity. With Equation (5) for f = 0.5 and l = 1.5 is illustrated in 
Figure 2
, where the force of social in-teraction is equal to zero for a distance of 2.079 units, and negative and positive for distances below and above 2.079 units, respectively. To put it another way, every grasshopper attracts grasshoppers that are further away than 2.079 units and repulses those that are closer. The safety zone is defined as 2.079 units in which neither soaking up nor disgust occurs. This function is approximately zero for distances greater than 4 units. As illustrated in 
Figure 2
, implying that grasshoppers cannot impact those that are further away. Equations (6) and (7) are used to determine the Fg
i
 and Aw
i
.













Fg




i




=


−


g








h


g






^




;










(6)
















Aw




i




=


u








h


w






^




,










(7)





where 










h


w






^






 and 










h


g






^






 indicate unity vectors in the direction of wind toward the centre of the earth, respectively, and g is the gravitational constants and u is the drift’s constant.
The formula in Equation (1) cannot be proposed for solving optimization issues since the search agents reach the comfort zone quickly and the swarm is not able to converge to a specific point. As a result, that model may be updated to:










P


i


n




=


m




(








∑














k


=


1














k


≠


i












N






r


c












ub




n




−






lb




n






2




s




(






|






p


j


n




−




p


i


n






|






)










p


j




−




p


i










d




ik












)




+








D


n






^












(8)




Here, 






r


c






 is a reduction coefficient to reduce the comfort zones, 










D


n






^






 is the target’s nth dimension value, and 








ub




n






 is the nth dimension’s upper bound, and 








lb




n






 is the nth dimension’s lower bound.
To equalize the exploration and exploitation phases, the 






r


c






 a variable must be decreased as the number of steps increases. To put it another way, the rate of investigation in the early phases must be higher than that of the later ones. As a result, 






r


c






 may be calculated as follows:










r


c




=




r


c










max






−


r








r


c










max






−




r


c










min








R












(9)










r


c










max








 and 






r


c










min








 are 1 and 0.00001, respectively, while R is the number of greatest iterations, and r is the number of the current iteration, respectively. The GOA’s specific processes are depicted in 
Figure 3
.
Single-objective and multi-objective optimization issues are two types of optimi-zation problems. Finding the optimum solution amongst these search agents is simple in single-objective algorithms. However, finding the optimum results in multi-objective algorithms (MOA) is quite difficult. As a result, MOGOA employs the dominance strategy. The two following agents A and B were required to apply. Agent A, according to this theory, has the upper hand against agent B if the following criteria are met:








∀


i


∈




(




1


,


2


,


…


,


k




)




:




f


i






(




Q


→




)




≤




f


i






(




Y


→




)




 


&


 


∃


i


∈




(




1


,


2


,


…


,


k




)




:




f


i






(




Q


→




)




<




f


i






(




Y


→




)












(10)




Here, Q and Y are the problem’s solution vectors. All non-dominated solutions (NDS) are collected in a repository termed Pareto optimal using a multi-objective op-timization method. For example, in 
Figure 4
, the black solutions (dots) are known as non-dominated, whereas the green solutions (dots) are known as a dominated (DS). The Pareto front is a collection of NDSs.
Finding the target in each cycle of an MOA counted as another difficulty. Sin-gle-optimization algorithms pick the best solution as its goal with ease, while MOAs have no best solution and instead have a group of NDSs. First, the region is split into several identical neighbourhoods to solve this problem. The chance of selecting the target from each neighbourhood is then calculated as follows:










Z


i




=




1






C


i








,










(11)





where Z
i
 denotes the likelihood of selecting the ith neighbourhood, and 






C


i






 represents the variety of solutions in that neighbourhood. During the last phase, a roulette wheel is used to select a target based on its probability. The repository’s capacity must be restricted; else, the computational cost would rise. Every incoming NDS will also be checked to the solution inside the old archive at each cycle. There are three possibilities in this case. If at least one archival solution dominates a new NDS, it is discarded. They are swapped whenever a fresh NDS takes over a stored solution. Eventually, a new NDS should be uploaded to the archive if it neither dominates nor is dominated by any existing stored solution. Introducing a new solution to the repository, on the other hand, might be an issue if the repository was already full. In this scenario, a procedure similar to the one used to choose the target with an opposing scoring system is employed to select a solution. 
Figure 5
 represents the different MOGO steps.
Throughout the 1940s, an artificial neural network (ANN) model based on the human brain and neural system was created to learn machines. In comparison to tradi-tional computers, the human brain is significantly better at solving new problems and processing information, while being slower [
15
]. ANNs are developed to do tasks like those performed by the human brain, utilizing data gathered from previous experiences. To address issues, ANNs use a variety of methods, the most prominent of which being feed-forward back-propagation (FFBP) [
16
]. FFBPs are the most often utilized ANNs in prior studies [
17
] due to their ease of application and ability to forecast.
FFPBs are made up of several layers, each with a distinct number of neurons. The first layer among these networks is the “input layer,” which receives inputs from the database and provides output values, while the last layer is the “output layer,” which produces output values. Neurons have the same number as the number of input and output values. In addition, between such two levels, there may be one or more hidden layers that do the processing. Every neuron in the following layer is connected to all the other neurons in the layer below via weighted connections one by one. Neurons and hidden layers’ number determines the ANN’s accuracy; nevertheless, as the network’s complexity increases, thus the accuracy increases [
15
,
16
,
18
]. 
Figure 6
 illustrates a mul-ti-layer ANN with a hidden layer.
Each neuron in the hidden layers gets several weighted inputs and a bias collects them and applies an activation function to produce a final value that is an input in the next layer. The input layer’s neurons have no purpose other than to receive data from the dataset, while the neurons of the output layer return their output (network output). Typically, linear activation functions are employed in the output layer for neurons, while hyperbolic tangent sigmoid activation functions are used in the hidden lay-ers(Kandiri, Mohammadi Golafshani, and Behnood 2020). An ANN’s schematic neuron is shown in 
Figure 7
.
The flux of information in Feed-forward ANNs flows from the input layer to the output layer, and the ANN predictions link weights throughout this process. In the backpropagation phase, meanwhile, learning algorithms such as gradient descent newton method, conjugate gradient, Levenberg-Marquardt algorithm, and qua-si-Newton method, to mention a few, are used to enhance the projected weights. In this research, Levenberg-Marquardt (LM) is employed since it performs better in the topic and is faster than other algorithms [
16
]. The revised weights and bias in the LM algo-rithm are computed as follows in Equation (12):












Wb






i


+


1






=






Wb




r




−








[






J


m








r






J


m




+








α


I






m






]








−


1








J


m








R




ε


,










(12)





where 








Wb






i


+


1








 is the updated biases and weights, 






J


m






 is the Jacobian matrix that considers the biases and weights for the first derivatives of the network errors, and 






I


m






, 


ε


, and 


α


 are identity matrix, vector of ANNs error, and positive real numbers damping factor, respectively.
The architecture of an ANN influences both speed and accuracy. ANN architectures are often characterized through trial and error. Nonetheless, a technique for achieving the optimum architecture must be developed. As a result, many optimal ANNs with varying amounts of hidden layers and neurons are required. MOGOA is crossed with an ANN in this research for that purpose. 
Figure 8
 shows the various stages of MOGOA’s hybridization with ANN (ANNMOGOA) with further explanation:
Data Normalization
Because the network error increases when multiple types of input with varying ranges are used, all data should be standardized. The following equation was being used to adjust inputs and outputs in the [−1, 1] range in this investigation.











e




norm






=






2




(




e


−




e




min








)










(






e




max






−




e




min








)








−


1










(13)










e




norm








, 






e




min








, and 






e




max








 are the normal, minimum, and maximum values of e, respectively.
Cross-validation using K-fold
Every ANN requires data collection to comprehend the output and input rela-tionship and anticipate undiscovered patterns. Furthermore, its performance must be confirmed during this procedure, and it must be tested in the end phase. As a result, the dataset is divided into three categories: training, validating, and testing. The k-fold cross-validation method is used in this study to reduce network over-fitting [
19
,
20
,
21
,
22
]. Following randomizing the dataset, it is split into k distinct folds of equally sized and the network is run for k times in this approach. Its first fold is utilized as a validating and testing dataset, while the remaining folds will be used as a training dataset. The second fold is then used to validate and test the network for the second time. Eventually, in the kth iteration, the kth fold is used to validate and test the ANN while the other folds are used to train it. The final result is the mean of all these k times of executing the ANN’s outputs. Every one of the patterns is being used for testing, validating, and training purposes as a result of this technique, making the ANN more accurate. The k-fold cross-validation approach is shown in 
Figure 9
.
Initializing MOGOA’s parameters
Every grasshopper position in this research is split into two halves, as shown in 
Figure 10
. The first component is a binary coding system that assigns a numerical value to the numbers of hidden layers. To put it another way, if the first part’s ith value is one, then ith hidden layer is active, and if its number is zero, the hidden layer is inactive. The number of hidden neurons in each hidden layer is indeed the subject of the second section. For example, part two of the position’s ith value reflects the number of neurons in the ith hidden layer.
Grasshopper’s positions initializing
Grasshoppers’ starting positions are produced at random using upper and lower limits.
Grasshopper’s performance computation
ANNMOGOA is a method for simultaneously reducing complexity and errors to the minimum level. A network error is defined as the mean error of the k-fold cross-validation technique. OBJ is also useful for comparing network performance be-cause it displays the mean absolute error (MAE), Pearson correlation coefficient (R), and root mean square (RMSE).









R


=








P


d








∑






i


=


1








P


d










R


e






R


m










(






P


d








∑






i


=


1








P


d










R


e


2




−








(








∑






i


=


1








P


d










R


e






)






2






)






(






P


d








∑






i


=


1








P


d










R


m


2




−








(








∑






i


=


1








P


d










R


m






)






2






)








;










(14)












RMSE


=








1






P


d












∑






i


=


1








P


d














(






R


e




−




R


m






)






2








;










(15)












MAE


=




1






P


d












∑






i


=


1








P


d










|






R


e




−




R


m






|




;










(16)












OBJ


=




(










T


t




−




T




vt












T


t




+




T




vt












)












RMSE




t




+






MAE




t










R


t




+


1






+




(








2




T




vt












T


t




+




T




vt












)












RMSE






vt






+






MAE






vt












R




vt






+


1














(17)




Here, T
vt
 is the number of patterns in the validation and testing part, T
t
 is the number of patterns in the training part, and 






P


d






 is the number of patterns in the dataset. The experimental analysis’ result is 






R


e






, and the model result is 






R


m






, which is connected to the d
th
 record [
23
,
24
]. The network’s complexity is defined in this study as the total of its weights and biases, which is calculated as follows:










Z




wb






=






∑






i


=


0




T






[






U


i






Q


i






(






Q




i


−




U




i


+


1






+


2






+


1




)






]




+




Q




i


+


1






−




Q


0












(18)




Here, 






U


0






 and 






U




i


+


1








 are both 1, 






Q


0






 is the number of neurons in the ANN’s input layer, 






Q


i






 is the number of neurons in the ANN’s ith hidden layer, and 






Q




i


+


1








 is the number of neurons in the ANN’s output layer [
25
].
Using MOGOA
Non-dominated grasshoppers are described in this phase and evaluated to grass-hoppers in the established repository. The complete none-dominated grasshoppers are then stored in the repository, then if the repository is full, a sufficient number of re-pository representatives are removed by using a technique described in the previous section. Following that, the location of the target will be adjusted using the method described above, and then the position of all grasshoppers will be adjusted. This process will be repeated till the last iteration is completed.
In order to define the strength of a concrete or a mortar, it is crucial to understand and consider its mix design. Many methods exist to accurately design the mix propor-tion of concrete, such as Building Research Establishment (BRE). However, it can be difficult to apply to all concrete types, and in particular to zero-slump concrete, which are the most used ones in 3DP concrete applications.
In this paper four effective parameters were used as ANN’s inputs: water-cement ratio (W/C), amount of coarse aggregate (CA), amount of fine aggregate (FA), amount of super-plasticizer (S). The only ANN’s output is the compressive strength (CS). 
Figure 11
 shows the detailed materials and frequency of used materials of cement and supplementary cementitious materials, such as fly ash (FA) and slag (S).
The fresh state of concrete or mortar is considered the most vital stage in the 3DP process. The way of handling operations is reflected in the product aesthetics of the printed structure and mechanical strength properties. 
Figure 12
 shows the general mix process and experimental programs which is necessary during the process of extrusion 3D printing.
Table 1
 shows the adjustment parameters determined through the trial-and-error method prior to running the model. After fitting the model 10 times, the Pareto front depicted in 
Figure 13
 is the best Pareto front. There are two axes in this graph: com-plexity and error. The OBJ value was utilized as the error in this study, while the com-plexity was defined as the number of connecting weights in the ANN. As it can be ob-served, there are five non-dominated grasshoppers on the Pareto front after generating 150,000 distinct ANNs, and the complexity is growing as the error reduces. In other words, a more accurate network comes with a more sophisticated structure. The archi-tectures of the simplest algorithm (ANNMOGOA-3) and more complex algorithm (ANNMOGOA-1) are shown in 
Figure 14
, and their weights and biases are listed in the 
Appendix B
.
A collection of statistical indicators is utilized to compare the behavior of the var-ious networks. Aside from the statistical indicators indicated in the technique section, the following parameters are used: mean bias error (MBE), mean absolute percentage error (MAPE), and scatter index (SI).









M


B


E


=




1


D








∑






i


=


1




D






(






R


d




−




O


d






)




;










(19)












M


A


P


E


=






100




D




 






∑






i


=


1




D










R


d




−


O








R


d








;










(20)












S


I


=


R


M


S


E


/




O


¯












(21)










O


d






 and 
O
 are the dth pattern’s experimental and average value experimental outcomes, respectively, 
D
 is the total number of patterns, and 






R


d






 is the dth pattern’s model result. If an ANN’s SI value is greater than 0.3, it has “poor performance,”; between 0.2 and 0.3, it has “fair performance”; between 0.1 and 0.2, it has “good performance”; and for less than 0.1, it has “excellent performance”, according to SI (Li et al., 2013). 
Table 2
 also includes the designs and complexity of all five networks, as well as statistical indicators for ANNs.
Table 2
 shows that ANNMOGOA-2 is the simplest network with 6 connecting weights and no hidden layers, followed by ANNMOGOA-7 with a single neuron in its hidden layer and 8 linking weights. ANNMOGOA-6, ANNMOGOA-3, ANNMOGOA-5, and ANNMOGOA-4 have 15, 22, 71, and 85 connecting weights, respectively. With fif-teen neurons in its only hidden layer and a complexity score of 106, ANNMOGOA-1 is the most complicated network. On the other hand, ANNMOGOA-1 is the most accurate model, with an OBJ value of 4.12, while ANNMOGOA-2 is the least accurate model, with an OBJ value of 23.28; all other models are in between. The RMSE of ANNMOGOA-1 is 4.49 MPa, which is about 75% lower than that of ANNMOGOA-2 with a value of 18.69. Furthermore, ANNMOGOA-2 has an MAE value of 14.47 MPa, which is about six times that of ANNMOGOA-1. Furthermore, when it comes to MAPE, the most accurate model is ANNMOGOA-1, which has a MAPE value of 8.75 percent, followed by ANNMOGOA-5, which has a MAPE value of 10.37 percent. The following five models are ANNMOGOA-4, ANNMOGOA-3, ANNMOGOA-6, ANNMOGOA-7, and ANNMOGOA-2, which have MAPE values of 13.17 percent, 16.66 percent, 20.25 percent, 27.60 percent, and 52.40 percent, respectively. So, ANNMOGOA-2 is the least accurate model. The Pearson correlation coefficient (R) measures the similarity between anticipated and measured values. This indication might be anything between 0 and 1. ANNMOGOA-1 has very good R-value that is equal 0.98. ANNMOGOA-2 and ANNMOGOA-7 have “poor performance”, whereas ANNMOGOA-1, ANNMOGOA-3, ANNMOGOA-4, and ANNMOGOA-5 have “good performances”, according to the SI value. ANNMOGOA-6 has “fair performances”. MBE illustrates ANNMOGOA-1, ANNMOGOA-5, and ANNMOGOA-6 overestimate the compressive strength while ANNMOGOA-2, ANNMOGOA-3, ANNMOGOA-4, and ANNMOGOA-7 underestimate that. 
Figure 15
 indicates the estimated values of models against measured values.
A bar chart is included in 
Figure 16
 to allow for a clearer comparison. They have the highest and lowest values for OBJ in ANNMOGOA-2 the ANNMOGOA-1, respectively, according to the bar chart, indicating that ANNMOGOA -1 is the best accurate model overall.
Future work is necessary to input further information in the processes of iteration for machine learning such as admixtures, different types of cement and supplementary cementitious materials. These materials are factors to change the result of calculation; however, it could not be always perfect due to the authors and journal publishers not being mandated to provide all data’s or sometimes due to secrets of production from industry not being permitted to publish those data. However, the concrete/mortar printing is not only affected by concrete mix proportion but also affected by other factors while handling the printing process and after printing processes such as humidity, temperature and curing condition.
Based on the present study, ANN can be used to predict the compressive strength of 3DP concrete. However, the difficulty of this method is that the accuracy of the model depends on the number of patterns. Unfortunately, there are still limited studies and patterns concerning 3DP concrete’s compressive strength. In contrast to the low number of patterns in the field, proposed model has acceptable results and by increasing the number of studies through time more accurate models can be developed.
Seven different networks with different complexities and accuracies are presented. From these algorithms, users can choose which model suits their project the most based on their limitations. It is obvious that if they need more accurate results they need to choose a network with a more complex structure.
Since the maximum number of hidden layers in this study is three, it is proved that for predicting 3DP concrete’s compressive strength, with a well-developed method, the results of a network with only one hidden layer can be accurate enough and there is no need for more complex net-works.
The correlation coefficient of three out of seven networks (ANNMOGOA-1, ANNMOGOA-4, and ANNMOGOA-5) is more than 0.96, which is accurate enough to be accepted.
Based on SI, four networks have good performance in predicting the compressive strength of 3DP concrete.
Considering MAPE, the accuracy of ANNMOGOA-1 is about 92%, which is a high value of accuracy.
Conceptualization, P.S.; methodology, H.I. and A.K.; software, H.I.; validation, A.K.; investigation, P.S.; data curation, V.L.; writing—original draft preparation, A.K., H.I. and P.S.; writing—review and editing, V.L. and P.S.; supervision, G.G. All authors have read and agreed to the published version of the manuscript.
This research is not received any grant and external funding.
The data and information reports will be available on request.
The authors declare no conflict of interest.
Biases and weights of the ANNMOGOA-1 model
 
Biases and weights of the ANNMOGOA-2 model
 
Biases and weights of the ANNMOGOA -3 model
 
Biases and weights of the ANNMOGOA -4 model
 
Biases and weights of the ANNMOGOA-5 model
 
Biases and weights of the ANNMOGOA-6 model
 
Biases and weights of the ANNMOGOA-7 model
 
Publisher’s Note:
 MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.