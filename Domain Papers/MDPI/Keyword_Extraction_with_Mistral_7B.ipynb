{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45VuZTjdewKq"
      },
      "source": [
        "**Source**: https://www.youtube.com/watch?v=xF2UJTmRU_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-e49bYW241gI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade git+https://github.com/UKPLab/sentence-transformers\n",
        "!pip install keybert ctransformers[cuda]\n",
        "!pip install --upgrade git+https://github.com/huggingface/transformers\n",
        "!pip install spacy\n",
        "!pip install yake\n",
        "!pip install gensim\n",
        "!pip install pyate\n",
        "!pip install rake-nltk\n",
        "!pip install summa\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install keybert\n",
        "!pip install huggingface_hu==0.10.1\n",
        "!pip install bibtexparser\n",
        "!pip install Levenshtein\n",
        "!pip install fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EnGxC3El6QSq"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "from ctransformers import AutoModelForCausalLM\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "from keybert.llm import TextGeneration\n",
        "from keybert import KeyLLM, KeyBERT\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eIE_nf2opzMg",
        "outputId": "bc305a81-078f-4cd8-ed58-0d1db710ba13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"hf_###\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayxmrmatCJc7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/mnt/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yoTEmSUROI-"
      },
      "outputs": [],
      "source": [
        "import bibtexparser\n",
        "from yake import KeywordExtractor\n",
        "from rake_nltk import Rake\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from yake import KeywordExtractor\n",
        "from rake_nltk import Rake\n",
        "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
        "from pyate import combo_basic, basic, cvalues\n",
        "from summa import keywords as summa_keywords\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from keybert import KeyBERT\n",
        "from nltk.stem import PorterStemmer\n",
        "from Levenshtein import distance\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from fuzzywuzzy import fuzz\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-W92b0sRQUS"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZRPR0ecBKDq"
      },
      "outputs": [],
      "source": [
        "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
        "    model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
        "    model_type=\"mistral\",\n",
        "    gpu_layers=50,\n",
        "    hf=True\n",
        ")\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
        "\n",
        "# Pipeline\n",
        "generator = pipeline(\n",
        "    model=model, tokenizer=tokenizer,\n",
        "    task='text-generation',\n",
        "    max_new_tokens=50,\n",
        "    repetition_penalty=1.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlOgU86TRT05"
      },
      "outputs": [],
      "source": [
        "def extract_keywords_from_abstract(abstract):\n",
        "\n",
        "    # Get the English stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    abstract = ' '.join([word for word in abstract.split() if word.lower() not in stop_words])\n",
        "\n",
        "    # Mistral7B\n",
        "    example_prompt = \"\"\"\n",
        "    <s>[INST]\n",
        "    I have the following document:\n",
        "    - Localized magnetic hyperthermia using magnetic nanoparticles (MNPs) under the application of small magnetic fields is a promising tool for treating small or deep-seated tumors.\n",
        "\n",
        "    Please give me the keywords that are present in this document and separate them with commas.\n",
        "    Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
        "    \"Here are the keywords present in the document\"\n",
        "    [/INST] localized magnetic hyperthermia,magnetic nanoparticles (MNPs),magnetic fields</s>\"\"\"\n",
        "\n",
        "    keyword_prompt = \"\"\"\n",
        "    [INST]\n",
        "\n",
        "    I have the following document:\n",
        "    - [DOCUMENT]\n",
        "\n",
        "    Please give me the keywords that are present in this document and separate them with commas.\n",
        "    Make sure you to only return the keywords and say nothing else. For example, don't say:\n",
        "    \"Here are the keywords present in the document\"\n",
        "    [/INST]\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = example_prompt + keyword_prompt\n",
        "\n",
        "    # Mistral7B\n",
        "    llm = TextGeneration(generator, prompt=prompt)\n",
        "    kw_model = KeyLLM(llm)\n",
        "    Mistral7B_keywords = kw_model.extract_keywords([abstract])[0]\n",
        "\n",
        "    # Mistral7B_embeddings\n",
        "    model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
        "    embeddings = model.encode([abstract], convert_to_tensor=True)\n",
        "    Mistral7B_embeddings_keywords = kw_model.extract_keywords([abstract], embeddings=embeddings, threshold=.5)[0]\n",
        "\n",
        "    # Mistral7B_KeyBERT\n",
        "    kw_model = KeyBERT(llm=llm, model='BAAI/bge-small-en-v1.5')\n",
        "    Mistral7B_KeyBERT_keywords = kw_model.extract_keywords([abstract], threshold=.5)[0]\n",
        "    return {\n",
        "        \"Mistral7B\": Mistral7B_keywords,\n",
        "        \"Mistral7B_embeddings\": Mistral7B_embeddings_keywords,\n",
        "        \"Mistral7B_KeyBERT\": Mistral7B_KeyBERT_keywords,\n",
        "\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEURTGyoR6K9"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "abstract = \"Functionalization facilitates targeted delivery of these nanoparticles to various cell types, bioimaging, gene delivery, drug delivery and other therapeutic and diagnostic applications.\"\n",
        "keywords = extract_keywords_from_abstract(abstract)\n",
        "for method, extracted_keywords in keywords.items():\n",
        "    print(method + \": \", extracted_keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5yPhE-VR73U"
      },
      "outputs": [],
      "source": [
        "# Function to tokenize and stem text\n",
        "def tokenize_and_stem(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    if isinstance(text, str):\n",
        "        tokens = [stemmer.stem(word) for word in text.split()]\n",
        "        return ' '.join(tokens)\n",
        "    else:\n",
        "        return str(text)\n",
        "\n",
        "# Function to calculate Levenshtein distance similarity\n",
        "def levenshtein_similarity(text1, text2):\n",
        "    return 1 - (distance(text1, text2) / max(len(text1), len(text2)))\n",
        "\n",
        "# Function to find synonyms using WordNet\n",
        "def find_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for synset in wordnet.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "# Function to calculate cosine similarity using TF-IDF\n",
        "def cosine_similarity_score(text1, text2):\n",
        "    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split())\n",
        "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "    return cosine_similarity(tfidf_matrix)[0][1]\n",
        "\n",
        "# Function to calculate fuzzy matching score\n",
        "def fuzzy_matching_score(text1, text2):\n",
        "    return fuzz.token_set_ratio(text1, text2)\n",
        "\n",
        "# Function to evaluate keywords\n",
        "def evaluate_keywords(ground_truth_keywords, extracted_keywords):\n",
        "    # Initialize variables for evaluation metrics\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "\n",
        "    # Tokenize and stem ground truth keywords\n",
        "    ground_truth_stems = [tokenize_and_stem(keyword) for keyword in ground_truth_keywords]\n",
        "\n",
        "    # Iterate over extracted keywords\n",
        "    for extracted_keyword in extracted_keywords:\n",
        "        # Tokenize and stem extracted keyword\n",
        "        extracted_stem = tokenize_and_stem(extracted_keyword)\n",
        "\n",
        "        # Check if extracted keyword matches any ground truth keyword\n",
        "        matched = False\n",
        "        for ground_truth_stem in ground_truth_stems:\n",
        "            # Calculate similarity scores\n",
        "            levenshtein_sim = levenshtein_similarity(extracted_stem, ground_truth_stem)\n",
        "            cosine_sim = cosine_similarity_score(extracted_stem, ground_truth_stem)\n",
        "            fuzzy_score = fuzzy_matching_score(extracted_keyword, ground_truth_stem)\n",
        "\n",
        "            # If any similarity score exceeds threshold, consider it a match\n",
        "            if levenshtein_sim > 0.8 or cosine_sim > 0.8 or fuzzy_score > 80:\n",
        "                matched = True\n",
        "                break\n",
        "\n",
        "        # Update evaluation metrics based on match status\n",
        "        if matched:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "\n",
        "    # Calculate false negatives (missed ground truth keywords)\n",
        "    fn = len(ground_truth_keywords) - tp\n",
        "\n",
        "    # Calculate precision, recall, and F1-score\n",
        "    if tp + fp > 0:\n",
        "        precision = tp / (tp + fp)\n",
        "    else:\n",
        "        precision = 0.0\n",
        "\n",
        "    if tp + fn > 0:\n",
        "        recall = tp / (tp + fn)\n",
        "    else:\n",
        "        recall = 0.0\n",
        "\n",
        "    if precision + recall > 0:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1_score = 0.0\n",
        "\n",
        "    return precision, recall, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQftyxNhSBA7"
      },
      "outputs": [],
      "source": [
        "def evaluate_keywords_from_bib(bib_file, extraction_functions, output_folder):\n",
        "    # Load the BibTeX file\n",
        "    with open(bib_file, 'r', encoding='utf-8') as bibfile:\n",
        "        bib_database = bibtexparser.load(bibfile)\n",
        "\n",
        "    # Initialize dictionaries to store cumulative scores\n",
        "    cumulative_precision = {method: 0 for method in extraction_functions}\n",
        "    cumulative_recall = {method: 0 for method in extraction_functions}\n",
        "    cumulative_f1_score = {method: 0 for method in extraction_functions}\n",
        "    total_abstracts = 0\n",
        "\n",
        "    # Initialize lists to store ground truth keywords, extracted keywords, and evaluation results\n",
        "    all_extracted_keywords = []\n",
        "    all_evaluation_results = []\n",
        "    all_evaluation_results_avg = []\n",
        "\n",
        "    # Iterate over entries in the BibTeX file\n",
        "    for entry in bib_database.entries:\n",
        "        # Check if the entry has abstract and keywords\n",
        "        if 'abstract' in entry and 'keywords' in entry:\n",
        "            abstract = entry['abstract'].lower()\n",
        "            ground_truth_keywords = entry['keywords'].split(',')\n",
        "            total_abstracts += 1\n",
        "\n",
        "            # Evaluate keywords for each extraction function\n",
        "            for method, extraction_function in extraction_functions.items():\n",
        "                extracted_keywords = extraction_function(abstract)\n",
        "                precision, recall, f1_score = evaluate_keywords(ground_truth_keywords, extracted_keywords)\n",
        "\n",
        "                # Accumulate scores\n",
        "                cumulative_precision[method] += precision\n",
        "                cumulative_recall[method] += recall\n",
        "                cumulative_f1_score[method] += f1_score\n",
        "\n",
        "                # Append data for CSV output\n",
        "                all_extracted_keywords.append((method, ground_truth_keywords, extracted_keywords))\n",
        "                all_evaluation_results.append((method, precision, recall, f1_score))\n",
        "\n",
        "    # Calculate averages\n",
        "    average_precision = {method: cumulative_precision[method] / total_abstracts for method in extraction_functions}\n",
        "    average_recall = {method: cumulative_recall[method] / total_abstracts for method in extraction_functions}\n",
        "    average_f1_score = {method: cumulative_f1_score[method] / total_abstracts for method in extraction_functions}\n",
        "\n",
        "    # Print average scores\n",
        "    print(\"Average Scores over all Abstracts:\")\n",
        "    for method in extraction_functions:\n",
        "        print(f\"Method      , Average Precision:                    , Average Recall:                    , Average F1-score:                    \")\n",
        "        print(f\"{method},{average_precision[method]},{average_recall[method]},{average_f1_score[method]}\")\n",
        "        all_evaluation_results_avg.append((method, average_precision[method], average_recall[method], average_f1_score[method]))\n",
        "\n",
        "    # Write ground truth keywords, extracted keywords, and evaluation results to CSV files\n",
        "    with open(os.path.join(output_folder, 'extracted_keywords.csv'), 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Method', 'Ground Truth Keywords', 'Extracted Keywords'])\n",
        "        writer.writerows(all_extracted_keywords)\n",
        "\n",
        "    with open(os.path.join(output_folder, 'evaluation_results.csv'), 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Method', 'Precision', 'Recall', 'F1-score'])\n",
        "        writer.writerows(all_evaluation_results)\n",
        "    \n",
        "    with open(os.path.join(output_folder, 'evaluation_results_avg.csv'), 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Method', 'Precision', 'Recall', 'F1-score'])\n",
        "        writer.writerows(all_evaluation_results_avg)\n",
        "\n",
        "# Define extraction functions\n",
        "extraction_functions = {\n",
        "    \"Mistral7B\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mistral7B\"],\n",
        "    \"Mistral7B_embeddings\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mistral7B_embeddings\"],\n",
        "    \"Mistral7B_KeyBERT\": lambda abstract: extract_keywords_from_abstract(abstract)[\"Mistral7B_KeyBERT\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u-D9D_OSDA8"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "bib_file = \"/mnt/drive/MyDrive/colab_data/nanomaterials-v01-i01_20240418.bib\"\n",
        "\n",
        "# Specify the output folder\n",
        "output_folder = \"/mnt/drive/MyDrive/colab_data/\"\n",
        "\n",
        "evaluate_keywords_from_bib(bib_file, extraction_functions, output_folder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
