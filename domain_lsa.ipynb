{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145cdd66",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ebrahim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "import re\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel, LdaModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rdflib import Graph\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc28d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, file_name):\n",
    "    \"\"\"\n",
    "    Input  : path and file_name\n",
    "    Purpose: loading text file\n",
    "    Output : list of paragraphs/documents, titles,\n",
    "             and subject lists\n",
    "    \"\"\"\n",
    "    titles = []\n",
    "    subjects_list = []\n",
    "\n",
    "    with open(\"output_2.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Extract titles from the content\n",
    "    collecting_title = False\n",
    "    current_title = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Title:\"):\n",
    "            # If we were previously collecting a title, we append it to the titles list\n",
    "            if collecting_title:\n",
    "                titles.append(current_title.strip())\n",
    "                current_title = \"\"\n",
    "            collecting_title = True\n",
    "            current_title += line.replace(\"Title:\", \"\").strip()\n",
    "        elif collecting_title:\n",
    "            current_title += \" \" + line.strip()\n",
    "\n",
    "    # Append the last title if any\n",
    "    if current_title:\n",
    "        titles.append(current_title.strip())\n",
    "    title_list = []\n",
    "    abstract_list = []\n",
    "    subject_list = []\n",
    "\n",
    "    for title in titles:\n",
    "        # Splitting on \"Abstract:\" and taking the first part as title and the second part as abstract\n",
    "        parts = title.split(\"Abstract:\")\n",
    "        \n",
    "        title_list.append(parts[0].strip())\n",
    "        abstract_list.append(parts[1].split(\" Subject:\")[0].strip())\n",
    "        subject_list.append(parts[1].split(\" Subject:\")[1].strip())\n",
    "\n",
    "    print(\"Total Number of Documents:\", len(abstract_list))\n",
    "\n",
    "    return abstract_list, title_list, subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e38632",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_data(doc_set, ngram_range=(1, 3)):\n",
    "    \"\"\"\n",
    "    Input  : document list\n",
    "    Purpose: preprocess text (tokenize, removing stopwords, and stemming)\n",
    "    Output : preprocessed text\n",
    "    \"\"\"\n",
    "    # Initialize regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # Create English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    # List for tokenized documents in loop\n",
    "    texts = []\n",
    "    # Loop through the document list\n",
    "    for i in doc_set:\n",
    "        # Clean and tokenize the document string\n",
    "        raw = i.lower()\n",
    "        raw = re.sub(r'(\\+)?\\d+[ ]?\\d*[ ]?\\d*[ ]?\\d*', ' ', raw)\n",
    "        # removing characters like ? ! : ; \\n \\\n",
    "        raw = re.sub('[*.?!,:;/&]', ' ', raw)\n",
    "        # removing words with fewer than 3 characters\n",
    "        raw = re.sub(r'\\b\\w{1,2}\\b', '', raw)\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # removing stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        \n",
    "        # Generate n-grams within the specified range\n",
    "        ngram_tokens = []\n",
    "        for n in range(ngram_range[0], ngram_range[1] + 1):\n",
    "            ngrams = list(nltk.ngrams(stopped_tokens, n))\n",
    "            ngram_tokens.extend(['_'.join(gram) for gram in ngrams])\n",
    "        \n",
    "        # Stem tokens (You can uncomment this line to perform stemming)\n",
    "        # stemmed_tokens = [p_stemmer.stem(i) for i in ngram_tokens]\n",
    "        stemmed_tokens = ngram_tokens\n",
    "        # Add tokens to the list\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "def prepare_corpus(doc_clean, include_bigrams=True):\n",
    "    \"\"\"\n",
    "    Input  : clean document\n",
    "    Purpose: create a term dictionary of our corpus and convert a list of documents (corpus) into a Document Term Matrix\n",
    "    Output : term dictionary and Document Term Matrix\n",
    "    \"\"\"\n",
    "    # Optionally, create bigrams if include_bigrams is True\n",
    "    if include_bigrams:\n",
    "        bigram = Phrases(doc_clean)\n",
    "        doc_clean = list(bigram[doc_clean])\n",
    "\n",
    "    # Creating the term dictionary of our corpus, where every unique term is assigned an index.\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "    # Converting the list of documents (corpus) into a Document Term Matrix using the dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "    return dictionary, doc_term_matrix\n",
    "\n",
    "from gensim.models.lsimodel import stochastic_svd\n",
    "\n",
    "def create_gensim_lsa_model(doc_clean, number_of_topics, words, include_bigrams=True):\n",
    "    \"\"\"\n",
    "    Input  : clean document, number of topics, and number of words associated with each topic\n",
    "    Purpose: create LSA model using gensim\n",
    "    Output : return LSA model\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    #preprocessed_text = preprocess_data(doc_clean)\n",
    "\n",
    "    # Generate LSA model with or without bigrams\n",
    "    dictionary, doc_term_matrix = prepare_corpus(doc_clean, include_bigrams=include_bigrams)\n",
    "    \n",
    "    # Initialize LSI model\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word=dictionary, chunksize= 1000)  # train model\n",
    "\n",
    "    return lsamodel, dictionary, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a619b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Documents: 64361\n"
     ]
    }
   ],
   "source": [
    "document_list,titles,subjects =load_data(\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8737b444-64e2-4121-b842-f5483c452061",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list,titles=document_list,titles\n",
    "clean_text=preprocess_data(document_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea065d2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics about the number of papers for each topic:\n",
      "- Condensed Matter Physics: 20571 papers\n",
      "- Electronic, Optical and Magnetic Materials: 7371 papers\n",
      "- Civil and Structural Engineering: 2011 papers\n",
      "- Ceramics and Composites: 3717 papers\n",
      "- General Materials Science: 17821 papers\n",
      "- Mechanics of Materials: 13175 papers\n",
      "- Metals and Alloys: 8432 papers\n",
      "- Mechanical Engineering: 11449 papers\n",
      "- Geology: 147 papers\n",
      "- Geotechnical Engineering and Engineering Geology: 344 papers\n",
      "- Multidisciplinary: 11 papers\n",
      "- Materials Chemistry: 17200 papers\n",
      "- Surfaces, Coatings and Films: 6907 papers\n",
      "- Surfaces and Interfaces: 5698 papers\n",
      "- Earth-Surface Processes: 46 papers\n",
      "- Materials Science (miscellaneous): 62 papers\n",
      "- Instrumentation: 3327 papers\n",
      "- Nuclear and High Energy Physics: 3791 papers\n",
      "- General Chemistry: 8765 papers\n",
      "- Electrical and Electronic Engineering: 2301 papers\n",
      "- General Chemical Engineering: 2772 papers\n",
      "- General Engineering: 3064 papers\n",
      "- Inorganic Chemistry: 2391 papers\n",
      "- Organic Chemistry: 2175 papers\n",
      "- Spectroscopy: 1043 papers\n",
      "- Analytical Chemistry: 896 papers\n",
      "- Polymers and Plastics: 2567 papers\n",
      "- Atomic and Molecular Physics, and Optics: 1357 papers\n",
      "- General Physics and Astronomy: 4021 papers\n",
      "- Geochemistry and Petrology: 522 papers\n",
      "- General Earth and Planetary Sciences: 398 papers\n",
      "- Computational Mathematics: 85 papers\n",
      "- General Computer Science: 99 papers\n",
      "- Physical and Theoretical Chemistry: 5011 papers\n",
      "- Space and Planetary Science: 391 papers\n",
      "- Physics and Astronomy (miscellaneous): 12 papers\n",
      "- Geophysics: 398 papers\n",
      "- Astronomy and Astrophysics: 359 papers\n",
      "- Applied Mathematics: 708 papers\n",
      "- General Mathematics: 212 papers\n",
      "- Energy Engineering and Power Technology: 1394 papers\n",
      "- Renewable Energy, Sustainability and the Environment: 511 papers\n",
      "- Earth and Planetary Sciences (miscellaneous): 33 papers\n",
      "- General Environmental Science: 252 papers\n",
      "- Biochemistry: 1193 papers\n",
      "- Food Science: 113 papers\n",
      "- General Medicine: 3490 papers\n",
      "- Pediatrics, Perinatology and Child Health: 50 papers\n",
      "- Surgery: 283 papers\n",
      "- Industrial and Manufacturing Engineering: 1553 papers\n",
      "- General Dentistry: 232 papers\n",
      "- Health, Toxicology and Mutagenesis: 279 papers\n",
      "- Pollution: 460 papers\n",
      "- Waste Management and Disposal: 524 papers\n",
      "- Environmental Chemistry: 608 papers\n",
      "- Environmental Engineering: 379 papers\n",
      "- Colloid and Surface Chemistry: 603 papers\n",
      "- Biomaterials: 908 papers\n",
      "- Molecular Biology: 83 papers\n",
      "- Biophysics: 325 papers\n",
      "- Process Chemistry and Technology: 601 papers\n",
      "- Filtration and Separation: 49 papers\n",
      "- Pharmaceutical Science: 190 papers\n",
      "- Biomedical Engineering: 136 papers\n",
      "- Biotechnology: 57 papers\n",
      "- Computer Science Applications: 671 papers\n",
      "- Modeling and Simulation: 746 papers\n",
      "- Building and Construction: 7945 papers\n",
      "- Statistics, Probability and Uncertainty: 4 papers\n",
      "- Statistics and Probability: 228 papers\n",
      "- Aerospace Engineering: 495 papers\n",
      "- Automotive Engineering: 42 papers\n",
      "- Computer Networks and Communications: 15 papers\n",
      "- Fluid Flow and Transfer Processes: 334 papers\n",
      "- Hardware and Architecture: 24 papers\n",
      "- Ocean Engineering: 40 papers\n",
      "- Safety, Risk, Reliability and Quality: 365 papers\n",
      "- Computational Mechanics: 14 papers\n",
      "- Catalysis: 722 papers\n",
      "- Fuel Technology: 492 papers\n",
      "- Management, Monitoring, Policy and Law: 114 papers\n",
      "- Computers in Earth Sciences: 2 papers\n",
      "- Global and Planetary Change: 5 papers\n",
      "- Radiation: 562 papers\n",
      "- Nuclear Energy and Engineering: 1741 papers\n",
      "- Electrochemistry: 406 papers\n",
      "- General Pharmacology, Toxicology and Pharmaceutics: 18 papers\n",
      "- General Biochemistry, Genetics and Molecular Biology: 15 papers\n",
      "- Engineering (miscellaneous): 25 papers\n",
      "- Chemical Engineering (miscellaneous): 22 papers\n",
      "- Bioengineering: 178 papers\n",
      "- Acoustics and Ultrasonics: 41 papers\n",
      "- Structural Biology: 21 papers\n",
      "- Computer Graphics and Computer-Aided Design: 10 papers\n",
      "- Analysis: 8 papers\n",
      "- Management Science and Operations Research: 58 papers\n",
      "- Strategy and Management: 140 papers\n",
      "- Obstetrics and Gynecology: 38 papers\n",
      "- General Social Sciences: 1 papers\n",
      "- Radiology, Nuclear Medicine and imaging: 224 papers\n",
      "- Rehabilitation: 76 papers\n",
      "- Orthopedics and Sports Medicine: 226 papers\n",
      "- Ecology, Evolution, Behavior and Systematics: 8 papers\n",
      "- Applied Microbiology and Biotechnology: 10 papers\n",
      "- Economic Geology: 13 papers\n",
      "- General Agricultural and Biological Sciences: 319 papers\n",
      "- Cell Biology: 45 papers\n",
      "- Genetics: 56 papers\n",
      "- Cardiology and Cardiovascular Medicine: 231 papers\n",
      "- Public Health, Environmental and Occupational Health: 87 papers\n",
      "- Neurology (clinical): 156 papers\n",
      "- Orthodontics: 29 papers\n",
      "- Gastroenterology: 24 papers\n",
      "- Health Informatics: 10 papers\n",
      "- Computer Vision and Pattern Recognition: 22 papers\n",
      "- Radiological and Ultrasound Technology: 21 papers\n",
      "- Pathology and Forensic Medicine: 28 papers\n",
      "- Animal Science and Zoology: 66 papers\n",
      "- Oceanography: 5 papers\n",
      "- Toxicology: 119 papers\n",
      "- Developmental Biology: 333 papers\n",
      "- General Neuroscience: 53 papers\n",
      "- Clinical Biochemistry: 34 papers\n",
      "- Psychiatry and Mental health: 87 papers\n",
      "- Geriatrics and Gerontology: 13 papers\n",
      "- Pharmacology: 86 papers\n",
      "- General Immunology and Microbiology: 15 papers\n",
      "- Transplantation: 11 papers\n",
      "- Emergency Medicine: 80 papers\n",
      "- Agronomy and Crop Science: 52 papers\n",
      "- Forestry: 47 papers\n",
      "- Food Animals: 18 papers\n",
      "- Aquatic Science: 19 papers\n",
      "- Emergency Nursing: 34 papers\n",
      "- Physical Therapy, Sports Therapy and Rehabilitation: 46 papers\n",
      "- Human Factors and Ergonomics: 15 papers\n",
      "- Pulmonary and Respiratory Medicine: 60 papers\n",
      "- Water Science and Technology: 52 papers\n",
      "- Sociology and Political Science: 10 papers\n",
      "- Developmental and Educational Psychology: 22 papers\n",
      "- Education: 33 papers\n",
      "- Biological Psychiatry: 49 papers\n",
      "- Endocrine and Autonomic Systems: 6 papers\n",
      "- Endocrinology: 45 papers\n",
      "- Endocrinology, Diabetes and Metabolism: 49 papers\n",
      "- Media Technology: 42 papers\n",
      "- Signal Processing: 33 papers\n",
      "- Soil Science: 33 papers\n",
      "- Optometry: 18 papers\n",
      "- Ophthalmology: 51 papers\n",
      "- Genetics (clinical): 4 papers\n",
      "- Neurology: 77 papers\n",
      "- Law: 10 papers\n",
      "- Dermatology: 17 papers\n",
      "- Immunology: 28 papers\n",
      "- Anesthesiology and Pain Medicine: 17 papers\n",
      "- Social Psychology: 11 papers\n",
      "- General Energy: 96 papers\n",
      "- History and Philosophy of Science: 2 papers\n",
      "- Health (social science): 7 papers\n",
      "- Medical–Surgical Nursing: 2 papers\n",
      "- Sensory Systems: 15 papers\n",
      "- Rheumatology: 10 papers\n",
      "- Nutrition and Dietetics: 30 papers\n",
      "- Geography, Planning and Development: 101 papers\n",
      "- Business and International Management: 8 papers\n",
      "- Chemistry (miscellaneous): 3 papers\n",
      "- Conservation: 3 papers\n",
      "- Archeology: 9 papers\n",
      "- General Economics, Econometrics and Finance: 3 papers\n",
      "- LPN and LVN: 10 papers\n",
      "- Speech and Hearing: 10 papers\n",
      "- Cognitive Neuroscience: 13 papers\n",
      "- Linguistics and Language: 9 papers\n",
      "- Language and Linguistics: 6 papers\n",
      "- Experimental and Cognitive Psychology: 25 papers\n",
      "- Applied Psychology: 10 papers\n",
      "- Microbiology: 18 papers\n",
      "- Human-Computer Interaction: 9 papers\n",
      "- General Veterinary: 35 papers\n",
      "- Dentistry (miscellaneous): 4 papers\n",
      "- Oral Surgery: 77 papers\n",
      "- Control and Systems Engineering: 55 papers\n",
      "- Cancer Research: 31 papers\n",
      "- Oncology: 44 papers\n",
      "- Otorhinolaryngology: 61 papers\n",
      "- General Nursing: 6 papers\n",
      "- Behavioral Neuroscience: 43 papers\n",
      "- Biochemistry (medical): 9 papers\n",
      "- Infectious Diseases: 59 papers\n",
      "- Parasitology: 13 papers\n",
      "- Insect Science: 6 papers\n",
      "- Veterinary (miscellaneous): 3 papers\n",
      "- Artificial Intelligence: 52 papers\n",
      "- Computational Theory and Mathematics: 3 papers\n",
      "- Physiology (medical): 35 papers\n",
      "- Clinical Psychology: 35 papers\n",
      "- Drug Discovery: 17 papers\n",
      "- Hematology: 15 papers\n",
      "- Molecular Medicine: 31 papers\n",
      "- Physiology: 341 papers\n",
      "- Hepatology: 16 papers\n",
      "- Critical Care and Intensive Care Medicine: 29 papers\n",
      "- Nephrology: 18 papers\n",
      "- Epidemiology: 21 papers\n",
      "- Atmospheric Science: 362 papers\n",
      "- Pharmacology (medical): 26 papers\n",
      "- Microbiology (medical): 32 papers\n",
      "- Urology: 17 papers\n",
      "- Immunology and Allergy: 32 papers\n",
      "- Histology: 8 papers\n",
      "- Reproductive Medicine: 21 papers\n",
      "- Software: 47 papers\n",
      "- General Psychology: 14 papers\n",
      "- Arts and Humanities (miscellaneous): 6 papers\n",
      "- Neuropsychology and Physiological Psychology: 12 papers\n",
      "- Medicine (miscellaneous): 17 papers\n",
      "- Nature and Landscape Conservation: 5 papers\n",
      "- Maternity and Midwifery: 1 papers\n",
      "- Economics and Econometrics: 42 papers\n",
      "- Ecological Modeling: 14 papers\n",
      "- Equine: 6 papers\n",
      "- Small Animals: 6 papers\n",
      "- Library and Information Sciences: 1 papers\n",
      "- Plant Science: 19 papers\n",
      "- Theoretical Computer Science: 5 papers\n",
      "- Information Systems and Management: 4 papers\n",
      "- Management Information Systems: 2 papers\n",
      "- Health Policy: 6 papers\n",
      "- Chiropractics: 11 papers\n",
      "- Virology: 12 papers\n",
      "- Architecture: 39 papers\n",
      "- Information Systems: 10 papers\n",
      "- Ecology: 11 papers\n",
      "- Transportation: 9 papers\n",
      "- General Business, Management and Accounting: 2 papers\n",
      "- Internal Medicine: 14 papers\n",
      "- Finance: 2 papers\n",
      "- Accounting: 4 papers\n",
      "- Developmental Neuroscience: 13 papers\n",
      "- Complementary and alternative medicine: 7 papers\n",
      "- Complementary and Manual Therapy: 2 papers\n",
      "- Care Planning: 1 papers\n",
      "- Oncology (nursing): 2 papers\n",
      "- Development: 1 papers\n",
      "- Cellular and Molecular Neuroscience: 5 papers\n",
      "- Management of Technology and Innovation: 3 papers\n",
      "- Marketing: 5 papers\n",
      "- Pshychiatric Mental Health: 3 papers\n",
      "- Horticulture: 10 papers\n",
      "- Energy (miscellaneous): 4 papers\n",
      "- Stratigraphy: 6 papers\n",
      "- Gerontology: 3 papers\n",
      "- Aging: 6 papers\n",
      "- Neuroscience (miscellaneous): 9 papers\n",
      "- Organizational Behavior and Human Resource Management: 5 papers\n",
      "- Numerical Analysis: 1 papers\n",
      "- Pharmacy: 3 papers\n",
      "- Pharmacology (nursing): 2 papers\n",
      "- Public Administration: 1 papers\n",
      "- Anthropology: 1 papers\n",
      "- Safety Research: 1 papers\n",
      "- Anatomy: 1 papers\n",
      "- Fundamentals and skills: 1 papers\n",
      "- Research and Theory: 1 papers\n",
      "- Leadership and Management: 1 papers\n",
      "- Communication: 1 papers\n",
      "- Life-span and Life-course Studies: 1 papers\n",
      "- Occupational Therapy: 4 papers\n",
      "- Critical Care Nursing: 2 papers\n",
      "- Issues, ethics and legal aspects: 1 papers\n",
      "- Agricultural and Biological Sciences (miscellaneous): 2 papers\n",
      "- Biochemistry, Genetics and Molecular Biology (miscellaneous): 1 papers\n",
      "- Family Practice: 1 papers\n",
      "- Statistical and Nonlinear Physics: 14 papers\n",
      "- History: 1 papers\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "subject_lists = [ast.literal_eval(subject_str) for subject_str in subjects]\n",
    "\n",
    "# Flatten the list of lists to get a single list of all topics\n",
    "all_topics = [topic for sublist in subject_lists for topic in sublist]\n",
    "\n",
    "# Count the occurrences of each topic\n",
    "topic_counts = Counter(all_topics)\n",
    "\n",
    "# Print statistics about the number of papers for each topic\n",
    "print(\"Statistics about the number of papers for each topic:\")\n",
    "for topic, count in topic_counts.items():\n",
    "    print(f\"- {topic}: {count} papers\")\n",
    "\n",
    "def papers_with_subject(abstracts, titles, subjects, target_subject):\n",
    "    \"\"\"\n",
    "    Return papers that have a specific subject in their subject list.\n",
    "    \"\"\"\n",
    "    papers_with_target_subject_abstracts = []\n",
    "    papers_with_target_subject_titles = []\n",
    "\n",
    "    for abstract, title, subject_list in zip(abstracts, titles, subjects):\n",
    "        if target_subject in subject_list:\n",
    "            papers_with_target_subject_abstracts.append(abstract)\n",
    "            papers_with_target_subject_titles.append(title)\n",
    "\n",
    "    return papers_with_target_subject_abstracts, papers_with_target_subject_titles\n",
    "\n",
    "target_subject = \"Metals and Alloys\"\n",
    "target_subject_abstracts, target_subject_titles = papers_with_subject(document_list, titles, subjects, target_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff2fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ebrahim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics:\n",
      "Number of topics: 64361\n",
      "Number of abstracts: 64361\n",
      "Total topic tokens: 578133\n",
      "Total abstract tokens: 5197254\n",
      "Unique topic tokens: 61358\n",
      "Unique abstract tokens: 237424\n",
      "\n",
      "Top 10 topic terms:\n",
      "temperature - 8208\n",
      "thermal - 6506\n",
      "properties - 5458\n",
      "effect - 4971\n",
      "transition - 4644\n",
      "alloys - 4612\n",
      "study - 4001\n",
      "x-ray - 3967\n",
      "cement - 3697\n",
      "high - 3264\n",
      "phase - 2674\n",
      "structure - 2592\n",
      "effects - 2556\n",
      "alloy - 2476\n",
      "diffraction - 2395\n",
      "concrete - 2370\n",
      "influence - 2292\n",
      "analysis - 2261\n",
      "using - 2243\n",
      "corrosion - 2225\n",
      "surface - 2197\n",
      "mechanical - 2105\n",
      "low - 1997\n",
      "wear - 1994\n",
      "conductivity - 1959\n",
      "behavior - 1916\n",
      "steel - 1886\n",
      "films - 1871\n",
      "aluminum - 1838\n",
      "test - 1768\n",
      "studies - 1761\n",
      "microstructure - 1642\n",
      "materials - 1635\n",
      "composite - 1630\n",
      "metal - 1617\n",
      "magnetic - 1611\n",
      "compression - 1537\n",
      "behaviour - 1522\n",
      "synthesis - 1515\n",
      "dependence - 1510\n",
      "composites - 1381\n",
      "electron - 1368\n",
      "characterization - 1360\n",
      "carbon - 1327\n",
      "performance - 1234\n",
      "formation - 1233\n",
      "method - 1229\n",
      "strength - 1211\n",
      "investigation - 1208\n",
      "system - 1203\n",
      "calcium - 1196\n",
      "growth - 1136\n",
      "oxide - 1115\n",
      "amorphous - 1075\n",
      "absorption - 1074\n",
      "electrical - 1067\n",
      "model - 1052\n",
      "thin - 1038\n",
      "structural - 1036\n",
      "spectroscopy - 1030\n",
      "neutron - 1013\n",
      "resistance - 1012\n",
      "crystal - 999\n",
      "glass - 997\n",
      "hydrogen - 987\n",
      "dispersion - 979\n",
      "oxidation - 966\n",
      "characteristics - 965\n",
      "pressure - 943\n",
      "electrochemical - 925\n",
      "based - 920\n",
      "energy - 920\n",
      "coatings - 917\n",
      "new - 902\n",
      "hydration - 895\n",
      "determination - 891\n",
      "water - 887\n",
      "ion - 881\n",
      "decomposition - 874\n",
      "solid - 870\n",
      "process - 867\n",
      "stability - 856\n",
      "reaction - 856\n",
      "heat - 853\n",
      "morphology - 841\n",
      "solution - 818\n",
      "de - 808\n",
      "preparation - 801\n",
      "experimental - 798\n",
      "single - 795\n",
      "portland - 790\n",
      "part - 780\n",
      "stress - 776\n",
      "emission - 773\n",
      "containing - 771\n",
      "chemical - 766\n",
      "phosphate - 765\n",
      "crystals - 764\n",
      "mechanism - 763\n",
      "measurements - 763\n",
      "\n",
      "Top 10 abstract terms:\n",
      "temperature - 35109\n",
      "results - 27229\n",
      "surface - 20996\n",
      "using - 20320\n",
      "phase - 18088\n",
      "high - 18076\n",
      "properties - 17430\n",
      "used - 15627\n",
      "found - 15535\n",
      "different - 15212\n",
      "thermal - 14891\n",
      "cement - 13952\n",
      "observed - 13921\n",
      "strength - 13788\n",
      "also - 13666\n",
      "structure - 13545\n",
      "effect - 13330\n",
      "study - 13276\n",
      "alloys - 13066\n",
      "investigated - 12884\n",
      "alloy - 12580\n",
      "x-ray - 12570\n",
      "rate - 12537\n",
      "two - 12504\n",
      "obtained - 12404\n",
      "studied - 11954\n",
      "method - 11900\n",
      "analysis - 11878\n",
      "wear - 11470\n",
      "process - 11160\n",
      "energy - 10984\n",
      "model - 10958\n",
      "electron - 10923\n",
      "samples - 10561\n",
      "low - 10495\n",
      "range - 10172\n",
      "formation - 10160\n",
      "transition - 10084\n",
      "concrete - 10029\n",
      "materials - 9988\n",
      "temperatures - 9884\n",
      "data - 9476\n",
      "higher - 9410\n",
      "test - 9336\n",
      "material - 9180\n",
      "due - 9132\n",
      "diffraction - 9056\n",
      "increase - 9032\n",
      "water - 8823\n",
      "corrosion - 8815\n",
      "compared - 8768\n",
      "experimental - 8686\n",
      "reaction - 8599\n",
      "conditions - 8580\n",
      "time - 8576\n",
      "size - 8323\n",
      "measured - 8206\n",
      "show - 8180\n",
      "showed - 8165\n",
      "solution - 8142\n",
      "mechanical - 8051\n",
      "measurements - 8016\n",
      "effects - 7840\n",
      "content - 7827\n",
      "resistance - 7810\n",
      "stress - 7714\n",
      "system - 7646\n",
      "films - 7503\n",
      "increased - 7444\n",
      "based - 7363\n",
      "determined - 7339\n",
      "layer - 7257\n",
      "addition - 7059\n",
      "well - 7016\n",
      "values - 7015\n",
      "steel - 6918\n",
      "tests - 6858\n",
      "growth - 6845\n",
      "particles - 6779\n",
      "paper - 6691\n",
      "prepared - 6641\n",
      "behavior - 6626\n",
      "ratio - 6594\n",
      "concentration - 6544\n",
      "one - 6530\n",
      "parameters - 6491\n",
      "increasing - 6378\n",
      "composite - 6358\n",
      "order - 6331\n",
      "discussed - 6331\n",
      "present - 6314\n",
      "pressure - 6284\n",
      "density - 6250\n",
      "conductivity - 6225\n",
      "shown - 6218\n",
      "however - 6185\n",
      "metal - 6164\n",
      "heat - 6122\n",
      "microscopy - 6060\n",
      "composition - 6052\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "# Download stop words set\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    # Simple function to tokenize text\n",
    "    tokens = text.split()\n",
    "    # Remove punctuation, convert to lowercase, and filter out single characters and numbers\n",
    "    return [token.strip(string.punctuation).lower() for token in tokens if token and len(token) > 1 and not token.isdigit() and token.lower() not in STOPWORDS]\n",
    "\n",
    "# Tokenize topics and abstracts\n",
    "topic_tokens = [tokenize(topic) for topic in titles]\n",
    "abstract_tokens = [tokenize(abstract) for abstract in document_list]\n",
    "\n",
    "# Flatten lists and get counts\n",
    "all_topic_tokens = [token for sublist in topic_tokens for token in sublist]\n",
    "all_abstract_tokens = [token for sublist in abstract_tokens for token in sublist]\n",
    "\n",
    "\n",
    "topic_counter = Counter(all_topic_tokens)\n",
    "abstract_counter = Counter(all_abstract_tokens)\n",
    "\n",
    "print(\"Statistics:\")\n",
    "print(\"Number of topics:\", len(titles))\n",
    "print(\"Number of abstracts:\", len(document_list))\n",
    "print(\"Total topic tokens:\", len(all_topic_tokens))\n",
    "print(\"Total abstract tokens:\", len(all_abstract_tokens))\n",
    "print(\"Unique topic tokens:\", len(topic_counter))\n",
    "print(\"Unique abstract tokens:\", len(abstract_counter))\n",
    "print(\"\\nTop 10 topic terms:\")\n",
    "for term, freq in topic_counter.most_common(100):\n",
    "    print(term, \"-\", freq)\n",
    "print(\"\\nTop 10 abstract terms:\")\n",
    "for term, freq in abstract_counter.most_common(100):\n",
    "    print(term, \"-\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f88683",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "number_of_topics=100\n",
    "words=3000\n",
    "model_, dictionary_, doc_term_matrix_ =create_gensim_lsa_model(clean_text, number_of_topics,words)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7208f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 18388\n"
     ]
    }
   ],
   "source": [
    "# Applying WordNet Expansion on words in LSA clusters\n",
    "\n",
    "unique_words_ = set()\n",
    "for i, _ in model_.show_topics():\n",
    "    topic = model_.show_topic(i, topn= 1000)\n",
    "    for word, score in topic:\n",
    "        unique_words_.add(word)\n",
    "               \n",
    "print(f'number of unique words: {len(unique_words_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f498c3ba-7dbe-46ba-b0a9-9b29cf69e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ebrahim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ebrahim/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# WordNet Term Expansion\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus.reader import Synset\n",
    "import json\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "def get_parents(obj):\n",
    "    \"\"\"\n",
    "    Get direct hypernyms\n",
    "    \"\"\"\n",
    "    return obj.hypernyms() + obj.instance_hypernyms()\n",
    "def _get_hierarchies(obj, level=-1):\n",
    "    \n",
    "    if level == 0:\n",
    "        # stop if reached a certain number of levels.\n",
    "        return [[]]\n",
    "    \n",
    "    parents = get_parents(obj)\n",
    "    if not parents:\n",
    "        return [[]]\n",
    "\n",
    "    hierarchies = []\n",
    "    for parent in parents:\n",
    "        tmp = _get_hierarchies(parent, level-1)\n",
    "        for hierarchy in tmp:\n",
    "            hierarchy.append(parent)\n",
    "        hierarchies = hierarchies + tmp\n",
    "    return hierarchies\n",
    "\n",
    "\n",
    "def get_hierarchies(word, level=-1):\n",
    "    normalized = word.lower().replace(' ', '_')\n",
    "    \n",
    "    # a single word may have multiple synsets\n",
    "    entries = wordnet.synsets(normalized, pos=wordnet.NOUN)\n",
    "    filtered_entries = list(filter(lambda x: normalized == x.lemma_names()[0].lower(), entries))\n",
    "\n",
    "    # only use filtered entries if something is left.\n",
    "    if filtered_entries:\n",
    "        entries = filtered_entries\n",
    "\n",
    "    hierarchies = []\n",
    "    for entry in entries:\n",
    "        hierarchies_of_entry = _get_hierarchies(entry, level)\n",
    "        for hierarchy in hierarchies_of_entry:\n",
    "            hierarchy.append(entry)\n",
    "            hierarchies.append(hierarchy)\n",
    "    return hierarchies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648d0287-f79d-4a5e-bb85-56f1f0785bbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_words_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      3\u001b[0m unique_words_expanded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43munique_words_\u001b[49m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Check if the word has three or fewer characters\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_words_' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "unique_words_expanded = set()\n",
    "\n",
    "for word in unique_words_:\n",
    "    # Check if the word has three or fewer characters\n",
    "    if len(word) <= 3:\n",
    "        continue\n",
    "    \n",
    "    # Check if the word contains a number using regular expressions\n",
    "    if re.search(r'\\d', word):\n",
    "        continue\n",
    "    \n",
    "    # Get WordNet hypernyms of two levels\n",
    "    hierarchies = get_hierarchies(word, 1)\n",
    "    \n",
    "    if not hierarchies:\n",
    "        # No expansion, append word as it is\n",
    "        unique_words_expanded.add(word.lower().replace('_', ' '))\n",
    "        continue\n",
    "        \n",
    "    # For every item in the hierarchy except the original\n",
    "    for hierarchy in hierarchies[:-1]:\n",
    "        for item in hierarchy:\n",
    "            for lemma_name in item.lemma_names():\n",
    "                word = lemma_name.lower().replace('_', ' ')\n",
    "                if len(word) <= 3:\n",
    "                    continue\n",
    "                \n",
    "                # Check if the word contains a number using regular expressions\n",
    "                if re.search(r'\\d', word):\n",
    "                    continue\n",
    "                unique_words_expanded.add(word)\n",
    "        break\n",
    "print(f'Number of unique words after WordNet expansion: {len(unique_words_expanded)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de9fd7fa-0875-42b1-9444-169fd56afd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract thought',\n",
       " 'accumulation',\n",
       " 'achieved',\n",
       " 'acier inoxydable',\n",
       " 'acoustic emission',\n",
       " 'acquisition',\n",
       " 'actinic radiation',\n",
       " 'actinic ray',\n",
       " 'action',\n",
       " 'activity',\n",
       " 'actuation',\n",
       " 'adhesive primer',\n",
       " 'adhesive primer plasma',\n",
       " 'adhesive systems',\n",
       " 'administrative district',\n",
       " 'administrative division',\n",
       " 'aggregation',\n",
       " 'ainsi que',\n",
       " 'air abrasion',\n",
       " 'air dry',\n",
       " 'air dry nitrogen',\n",
       " 'alkali content',\n",
       " 'alkali silica',\n",
       " 'alkali silica reaction silica reaction asr',\n",
       " 'alkali silica silica reaction',\n",
       " 'alkaline media',\n",
       " 'allowing generation fan',\n",
       " 'alloy',\n",
       " 'also',\n",
       " 'also affected',\n",
       " 'also observed',\n",
       " 'alteration',\n",
       " 'aluminum alloy',\n",
       " 'ammoniaque',\n",
       " 'amorphous',\n",
       " 'amount',\n",
       " 'amusement',\n",
       " 'analyzed',\n",
       " 'analyzed detail',\n",
       " 'analyzed using',\n",
       " 'angular pressing',\n",
       " 'animal material',\n",
       " 'applied stress',\n",
       " 'après',\n",
       " 'arc light curing',\n",
       " 'arisen',\n",
       " 'around',\n",
       " 'around joint',\n",
       " 'around joint intersection',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'artefact',\n",
       " 'artifact',\n",
       " 'asr development',\n",
       " 'asr gel',\n",
       " 'asr test',\n",
       " 'assemblage',\n",
       " 'attrition wear',\n",
       " 'aucun',\n",
       " 'aucun effet',\n",
       " 'avec une',\n",
       " 'axial compression',\n",
       " 'barrière',\n",
       " 'barrière potentiel',\n",
       " 'based',\n",
       " 'based alloys',\n",
       " 'based materials',\n",
       " 'based yld',\n",
       " 'based yld yield',\n",
       " 'became',\n",
       " 'became narrower',\n",
       " 'became narrower narrower',\n",
       " 'belief',\n",
       " 'binary compound',\n",
       " 'biological group',\n",
       " 'biological process',\n",
       " 'blended cement',\n",
       " 'blended portland',\n",
       " 'blended portland portland cement',\n",
       " 'body',\n",
       " 'body part',\n",
       " 'bond strength',\n",
       " 'bottom surface',\n",
       " 'brace chord',\n",
       " 'brace chord width',\n",
       " 'branch',\n",
       " 'building material',\n",
       " 'bulk fill',\n",
       " 'calcium silicate',\n",
       " 'calculated',\n",
       " 'carbon fiber',\n",
       " 'carbon ion',\n",
       " 'carbone',\n",
       " 'case',\n",
       " 'cavity',\n",
       " 'cbh model',\n",
       " 'cement based',\n",
       " 'cement based based materials',\n",
       " 'cement based materials',\n",
       " 'cement clinker',\n",
       " 'cement composites',\n",
       " 'cement concrete',\n",
       " 'cement content',\n",
       " 'cement fly fly ash',\n",
       " 'cement hydration',\n",
       " 'cement matrix',\n",
       " 'cement mortar',\n",
       " 'cement mortars',\n",
       " 'cement paste',\n",
       " 'cement pastes',\n",
       " 'cement ratio',\n",
       " 'cementitious materials',\n",
       " 'ceramic material',\n",
       " 'ceramic materials',\n",
       " 'ceramic stylus',\n",
       " 'certificate of indebtedness',\n",
       " 'cette opération',\n",
       " 'cette étude',\n",
       " 'cfci life',\n",
       " 'chaboche',\n",
       " 'chaboche hardening',\n",
       " 'chaboche hardening law',\n",
       " 'change',\n",
       " 'change observed',\n",
       " 'chemical element',\n",
       " 'chloride concentration',\n",
       " 'chloride ions',\n",
       " 'chord member',\n",
       " 'chord member around',\n",
       " 'chord width',\n",
       " 'chord width ratio',\n",
       " 'chromium alloy',\n",
       " 'chs joints',\n",
       " 'circumstance',\n",
       " 'coarse aggregate',\n",
       " 'coarse grained',\n",
       " 'cobalt chromium',\n",
       " 'cobalt chromium alloy',\n",
       " 'coefficient friction',\n",
       " 'coefficients friction',\n",
       " 'cognition',\n",
       " 'collection',\n",
       " 'combined effect',\n",
       " 'combined loading',\n",
       " 'combined loading loading paths',\n",
       " 'combined loading paths',\n",
       " 'compact tension',\n",
       " 'compared',\n",
       " 'compared theoretical',\n",
       " 'component',\n",
       " 'component part',\n",
       " 'composition',\n",
       " 'compressive strength',\n",
       " 'compressive strengths',\n",
       " 'concave chord',\n",
       " 'concrete',\n",
       " 'concrete made',\n",
       " 'concrete mixes',\n",
       " 'concrete specimens',\n",
       " 'concrete structures',\n",
       " 'condition',\n",
       " 'conductivité',\n",
       " 'conduit',\n",
       " 'confining pressure',\n",
       " 'consistence',\n",
       " 'consistency',\n",
       " 'constituent',\n",
       " 'contact angle',\n",
       " 'contact force',\n",
       " 'context',\n",
       " 'continuous',\n",
       " 'contraction force',\n",
       " 'conventional halogen',\n",
       " 'conventional visible',\n",
       " 'conventional visible light',\n",
       " 'corresponding stress',\n",
       " 'corrosion products',\n",
       " 'corrosion rate',\n",
       " 'corrosion resistance',\n",
       " 'corrosion très',\n",
       " 'could achieved',\n",
       " 'course',\n",
       " 'course of action',\n",
       " 'covering',\n",
       " 'crack growth',\n",
       " 'crack initiation',\n",
       " 'crack propagation',\n",
       " 'crack tip',\n",
       " 'creep strain',\n",
       " 'creep strain rate',\n",
       " 'crevice effect',\n",
       " 'critical concentration',\n",
       " 'critical level',\n",
       " 'crushed brick',\n",
       " 'crystallization temperature',\n",
       " 'crystallization temperature pulling',\n",
       " 'csa cement',\n",
       " 'cure time',\n",
       " 'cured',\n",
       " 'curing acrylic',\n",
       " 'curing acrylic resin',\n",
       " 'curing temperature',\n",
       " 'current practice',\n",
       " 'cyclic loading',\n",
       " 'cylindrite',\n",
       " 'cylindrite achieved',\n",
       " 'cylindrite achieved readily',\n",
       " 'cylindrite became',\n",
       " 'cylindrite became narrower',\n",
       " 'cylindrite mixed',\n",
       " 'cylindrite rich',\n",
       " 'cylindrite rich cylindrite',\n",
       " 'damage evolution',\n",
       " 'dans',\n",
       " 'dans cas',\n",
       " 'dans des',\n",
       " 'dans des solutions',\n",
       " 'dans eau',\n",
       " 'dans les',\n",
       " 'dans une',\n",
       " 'debt instrument',\n",
       " 'deformation',\n",
       " 'deformation work',\n",
       " 'deformation work roll',\n",
       " 'degree',\n",
       " 'degree hydration',\n",
       " 'densely distributed',\n",
       " 'dependent phase',\n",
       " 'depth cure',\n",
       " 'des alliages',\n",
       " 'des concentrations',\n",
       " 'des effets',\n",
       " 'des effets crevasse',\n",
       " 'des essais',\n",
       " 'des solutions',\n",
       " 'des solutions lithine',\n",
       " 'des températures',\n",
       " 'des éprouvettes',\n",
       " 'design equations',\n",
       " 'deterioration',\n",
       " 'determine whether',\n",
       " 'determined',\n",
       " 'deux cas',\n",
       " 'device',\n",
       " 'diagram polymorphs',\n",
       " 'diagram polymorphs ipp',\n",
       " 'diagrams made',\n",
       " 'diamond films',\n",
       " 'dielectric losses',\n",
       " 'different',\n",
       " 'different loading',\n",
       " 'dioxide',\n",
       " 'disagreeable person',\n",
       " 'dislocation density',\n",
       " 'domain independent',\n",
       " 'domain independent pull',\n",
       " 'drawing process',\n",
       " 'dry mix',\n",
       " 'dry mix glass',\n",
       " 'dry nitrogen',\n",
       " 'drying shrinkage',\n",
       " 'dynamic impact',\n",
       " 'early age',\n",
       " 'effect observed',\n",
       " 'effect strain',\n",
       " 'effectively used',\n",
       " 'effects observed',\n",
       " 'effectuer',\n",
       " 'effet',\n",
       " 'effet crevasse',\n",
       " 'effets',\n",
       " 'effets crevasse',\n",
       " 'elastic deformation',\n",
       " 'elastic phase',\n",
       " 'elastic plastic',\n",
       " 'elasticity ultimate',\n",
       " 'elasticity ultimate tensile',\n",
       " 'electrical conductivity',\n",
       " 'electron hops',\n",
       " 'element',\n",
       " 'elevated temperatures',\n",
       " 'enclosed space',\n",
       " 'energy barrier',\n",
       " 'engineering application',\n",
       " 'enlargement',\n",
       " 'entertainment',\n",
       " 'entre',\n",
       " 'equipment',\n",
       " 'equivalent plastic',\n",
       " 'essais',\n",
       " 'essais dans',\n",
       " 'eubstance',\n",
       " 'evolution microstructure',\n",
       " 'examens micrographiques',\n",
       " 'example',\n",
       " 'excavation',\n",
       " 'exemple',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experimental flds',\n",
       " 'experimental results',\n",
       " 'experimentation',\n",
       " 'experiments carried',\n",
       " 'explanation',\n",
       " 'faces contact',\n",
       " 'failure concrete',\n",
       " 'failure load',\n",
       " 'failure load initial',\n",
       " 'failure loads',\n",
       " 'failure loads steel',\n",
       " 'fan shaped',\n",
       " 'fan shaped domain',\n",
       " 'fatigue crack crack growth',\n",
       " 'fatigue life',\n",
       " 'feeling',\n",
       " 'fiber composites',\n",
       " 'fiber reinforced',\n",
       " 'findings study',\n",
       " 'fine grain',\n",
       " 'fine grain diamond',\n",
       " 'fine grained',\n",
       " 'finite element',\n",
       " 'first second',\n",
       " 'first ultimate',\n",
       " 'first ultimate limit',\n",
       " 'fissure sealants',\n",
       " 'fld much',\n",
       " 'fld much less',\n",
       " 'fld strain',\n",
       " 'fld stress',\n",
       " 'fld stress fld',\n",
       " 'flds',\n",
       " 'flds strain',\n",
       " 'flds strain combined',\n",
       " 'flexural strength',\n",
       " 'flow stress',\n",
       " 'fly ash ash cement',\n",
       " 'fly ash cement',\n",
       " 'fly ash concrete',\n",
       " 'form',\n",
       " 'formed',\n",
       " 'forming limit',\n",
       " 'forming limit diagrams',\n",
       " 'forming limits',\n",
       " 'found among',\n",
       " 'four combined',\n",
       " 'four combined loading',\n",
       " 'fraction reacted',\n",
       " 'fracture toughness',\n",
       " 'freeze thaw',\n",
       " 'frequency dependent',\n",
       " 'friction wear',\n",
       " 'function chaboche',\n",
       " 'function chaboche hardening',\n",
       " 'function frequency',\n",
       " 'fundamental measure',\n",
       " 'fundamental quantity',\n",
       " 'gazeuse',\n",
       " 'generated',\n",
       " 'given cure',\n",
       " 'glass concrete',\n",
       " 'good agreement',\n",
       " 'grade',\n",
       " 'gradient grained',\n",
       " 'grain boundaries',\n",
       " 'grain boundary',\n",
       " 'grain diamond',\n",
       " 'grain diamond films',\n",
       " 'grain refinement',\n",
       " 'grain size',\n",
       " 'grout strength',\n",
       " 'growth data',\n",
       " 'halogen lcu',\n",
       " 'hardened cement',\n",
       " 'hardening law',\n",
       " 'hardening model',\n",
       " 'harm',\n",
       " 'heat transfer',\n",
       " 'heat treatment',\n",
       " 'hexafluoride',\n",
       " 'hexafluorure',\n",
       " 'high proportion',\n",
       " 'high speed',\n",
       " 'high strain',\n",
       " 'high strength',\n",
       " 'high volume',\n",
       " 'high volume fly volume fly ash',\n",
       " 'high volume volume fly',\n",
       " 'high-angle gun',\n",
       " 'higher',\n",
       " 'hma rutting',\n",
       " 'hma shear',\n",
       " 'hole',\n",
       " 'hollow ratio',\n",
       " 'hollow ratio chord',\n",
       " 'however',\n",
       " 'however obvious',\n",
       " 'humid air',\n",
       " 'hurt',\n",
       " 'hybrid process',\n",
       " 'hybrid process route',\n",
       " 'hydrated oxide',\n",
       " 'hydration degree',\n",
       " 'hydration kinetics',\n",
       " 'hydration process',\n",
       " 'hydration products',\n",
       " 'hydroxide',\n",
       " 'hydroxide solution',\n",
       " 'hydroxide solutions',\n",
       " 'hypothesis',\n",
       " 'idea',\n",
       " 'identical pure',\n",
       " 'illustration',\n",
       " 'impairment',\n",
       " 'implying',\n",
       " 'implying sudden',\n",
       " 'implying sudden transition',\n",
       " 'importance',\n",
       " 'impression',\n",
       " 'increase htt',\n",
       " 'increase ratio',\n",
       " 'increased',\n",
       " 'increasing pull',\n",
       " 'increasing pull implying',\n",
       " 'incremental displacement',\n",
       " 'independent pull',\n",
       " 'independent pull around',\n",
       " 'independent temperature',\n",
       " 'individualist',\n",
       " 'induced',\n",
       " 'inflection',\n",
       " 'influence',\n",
       " 'initial stiffness',\n",
       " 'injury',\n",
       " 'inner tube chord',\n",
       " 'insoluble residue',\n",
       " 'instance',\n",
       " 'instrumentality',\n",
       " 'instrumentation',\n",
       " 'intensive shearing upper',\n",
       " 'interaction',\n",
       " 'interfacial',\n",
       " 'interfacial zone',\n",
       " 'interlaminar shear',\n",
       " 'internal stress',\n",
       " 'intersection region',\n",
       " 'intriguing',\n",
       " 'intriguing suggest',\n",
       " 'intriguing suggest temperature',\n",
       " 'investigate effects',\n",
       " 'investigated',\n",
       " 'investigating',\n",
       " 'investigation',\n",
       " 'ion chelator',\n",
       " 'ion implanted',\n",
       " 'ipp carbon',\n",
       " 'ipp carbon fiber',\n",
       " 'irradiation creep',\n",
       " 'isotactic polypropylene',\n",
       " 'ivoclar method',\n",
       " 'joint intersection',\n",
       " 'joint intersection region',\n",
       " 'joints axial',\n",
       " 'joints axial compression',\n",
       " 'joints improved',\n",
       " 'joints large',\n",
       " 'joints large ratio',\n",
       " 'jours',\n",
       " 'jump tests',\n",
       " 'kind',\n",
       " 'know-how',\n",
       " 'knowledge',\n",
       " 'lagrangian formulation',\n",
       " 'large pores',\n",
       " 'large ratio',\n",
       " 'larger obtained',\n",
       " 'learning',\n",
       " 'led lcu',\n",
       " 'les examens',\n",
       " 'les faces',\n",
       " 'les faces contact',\n",
       " 'les joints',\n",
       " 'les produits',\n",
       " 'les propriétés',\n",
       " 'les résultats',\n",
       " 'less fld',\n",
       " 'less fld strain',\n",
       " 'level',\n",
       " 'ligament',\n",
       " 'light curing',\n",
       " 'light curing curing unit',\n",
       " 'light curing unit',\n",
       " 'lightweight concrete',\n",
       " 'limit',\n",
       " 'limit diagrams',\n",
       " 'limit diagrams made',\n",
       " 'line',\n",
       " 'liquid chromatography',\n",
       " 'lithine',\n",
       " 'lithium hydroxide',\n",
       " 'lithium hydroxide solution',\n",
       " 'lithium salts',\n",
       " 'load initial',\n",
       " 'load initial stiffness',\n",
       " 'loading path',\n",
       " 'loading paths',\n",
       " 'loading paths obtained',\n",
       " 'loading paths pre',\n",
       " 'loads steel',\n",
       " 'loads steel concrete',\n",
       " 'localized corrosion',\n",
       " 'localized sites',\n",
       " 'location',\n",
       " 'logical thinking',\n",
       " 'low wear',\n",
       " 'made possible',\n",
       " 'magnitude',\n",
       " 'magnitude relation',\n",
       " 'material',\n",
       " 'may attributed',\n",
       " 'measure',\n",
       " 'measured',\n",
       " 'mechanical properties',\n",
       " 'member around',\n",
       " 'member around joint',\n",
       " 'mental measurement',\n",
       " 'mercury intrusion',\n",
       " 'metal',\n",
       " 'metallic glasses',\n",
       " 'methods adopted',\n",
       " 'mettre évidence',\n",
       " 'micro',\n",
       " 'micro hardness',\n",
       " 'micro tomography',\n",
       " 'micrographic examination',\n",
       " 'microhardness top',\n",
       " 'microhardness top surface',\n",
       " 'microhardness wear',\n",
       " 'microscopy sem',\n",
       " 'microstructure',\n",
       " 'mis évidence',\n",
       " 'mix dry',\n",
       " 'mix dry mix',\n",
       " 'mix glass concrete',\n",
       " 'mix glass glass concrete',\n",
       " 'mix method',\n",
       " 'mixed cylindrite',\n",
       " 'mixed cylindrite rich',\n",
       " 'mixture',\n",
       " 'model cannot',\n",
       " 'modification',\n",
       " 'modified mortars',\n",
       " 'moduli elasticity',\n",
       " 'modulus elasticity',\n",
       " 'much less',\n",
       " 'much less fld',\n",
       " 'musical group',\n",
       " 'musical organisation',\n",
       " 'musical organization',\n",
       " 'métal',\n",
       " 'méthodes',\n",
       " 'narrower',\n",
       " 'natural diamond',\n",
       " 'natural pozzolan',\n",
       " 'near',\n",
       " 'new cracks',\n",
       " 'noesis',\n",
       " 'non destructive',\n",
       " 'non faceted',\n",
       " 'nonaccomplishment',\n",
       " 'nonachievement',\n",
       " 'notion',\n",
       " 'number sites',\n",
       " 'obligation',\n",
       " 'observed',\n",
       " 'obtained',\n",
       " 'obtained fld',\n",
       " 'obtained fld strain',\n",
       " 'obtained two',\n",
       " 'obtained two pass',\n",
       " 'ohsu method',\n",
       " 'ont été',\n",
       " 'opc concrete',\n",
       " 'opening',\n",
       " 'opinion',\n",
       " 'organic process',\n",
       " 'organisation',\n",
       " 'organization',\n",
       " 'outer tube',\n",
       " 'oxydation',\n",
       " 'paper presents',\n",
       " 'par les',\n",
       " 'parameters allows',\n",
       " 'parcel',\n",
       " 'parcel of land',\n",
       " 'part',\n",
       " 'partir',\n",
       " 'parts mass',\n",
       " 'pass hybrid',\n",
       " 'pass hybrid process',\n",
       " 'pass wire',\n",
       " 'pass wire drawing',\n",
       " 'paths obtained',\n",
       " 'paths pre',\n",
       " 'performance concrete',\n",
       " 'period',\n",
       " 'period of time',\n",
       " 'permeability coefficients',\n",
       " 'permet',\n",
       " 'permittivity',\n",
       " 'pesées',\n",
       " 'pet substrate',\n",
       " 'phase diagram',\n",
       " 'phenomenon',\n",
       " 'physical phenomenon',\n",
       " 'physical process',\n",
       " 'piece',\n",
       " 'piece of ground',\n",
       " 'piece of land',\n",
       " 'pit fissure',\n",
       " 'placement',\n",
       " 'plain concrete',\n",
       " 'plant organ',\n",
       " 'plasma arc',\n",
       " 'plasma arc arc light',\n",
       " 'plasma arc light',\n",
       " 'plasma treatment',\n",
       " 'plastic deformation',\n",
       " 'plastic strain',\n",
       " 'point',\n",
       " 'polymer cement',\n",
       " 'polymorphic structure',\n",
       " 'pore geometries',\n",
       " 'pore solution',\n",
       " 'pore space',\n",
       " 'pore structure',\n",
       " 'porosimetry mip',\n",
       " 'porosity measured',\n",
       " 'portion',\n",
       " 'possession',\n",
       " 'possibility',\n",
       " 'potential barrier',\n",
       " 'potentiel',\n",
       " 'pour',\n",
       " 'pour des',\n",
       " 'pour les',\n",
       " 'power',\n",
       " 'powerfulness',\n",
       " 'pozzolanic activity',\n",
       " 'pozzolanic reaction',\n",
       " 'pre strain',\n",
       " 'pre strains',\n",
       " 'prediction forming',\n",
       " 'prediction forming limit',\n",
       " 'prepared',\n",
       " 'prepared wet',\n",
       " 'present study',\n",
       " 'pression',\n",
       " 'primer plasma',\n",
       " 'primer plasma treatment',\n",
       " 'principal stresses',\n",
       " 'process',\n",
       " 'process route',\n",
       " 'processed two',\n",
       " 'processed two pass',\n",
       " 'product',\n",
       " 'production',\n",
       " 'produit',\n",
       " 'produits corrosion',\n",
       " 'properties cement',\n",
       " 'properties concrete',\n",
       " 'property',\n",
       " 'proposal',\n",
       " 'proposed based',\n",
       " 'propulsion',\n",
       " 'prosody',\n",
       " 'préciser les',\n",
       " 'pulling rate',\n",
       " 'pulling rate pull',\n",
       " 'pure',\n",
       " 'pvc inner',\n",
       " 'pvc inner tube',\n",
       " 'pvc shs',\n",
       " 'pvc shs joints',\n",
       " 'pvc shs shs joints',\n",
       " 'quality',\n",
       " 'quantitative relation',\n",
       " 'quantity',\n",
       " 'que celle',\n",
       " 'ramification',\n",
       " 'rank',\n",
       " 'rate pull',\n",
       " 'ratio',\n",
       " 'ratio chord',\n",
       " 'ratio hollow',\n",
       " 'ratio hollow ratio',\n",
       " 'ray computed',\n",
       " 'ray diffraction',\n",
       " 'ray μct',\n",
       " 'reaction asr',\n",
       " 'readily',\n",
       " 'reasoning',\n",
       " 'recent study',\n",
       " 'reduction rate',\n",
       " 'region',\n",
       " 'reinforcement',\n",
       " 'reinforcement corrosion',\n",
       " 'remains unclear',\n",
       " 'replacement level',\n",
       " 'reported previous',\n",
       " 'representative',\n",
       " 'research project',\n",
       " 'residual stress',\n",
       " 'residual stresses',\n",
       " 'resin composites',\n",
       " 'respectively',\n",
       " 'results indicate',\n",
       " 'results show',\n",
       " 'results showed',\n",
       " 'reverse phase',\n",
       " 'rheological properties',\n",
       " 'rich cylindrite',\n",
       " 'rolling process',\n",
       " 'root brace',\n",
       " 'scientific research',\n",
       " 'self compacting',\n",
       " 'self compacting cement compacting cement paste',\n",
       " 'self compacting compacting cement',\n",
       " 'self curing',\n",
       " 'self curing acrylic',\n",
       " 'self etch',\n",
       " 'self lubricating',\n",
       " 'sensation',\n",
       " 'sense',\n",
       " 'sensory faculty',\n",
       " 'sentience',\n",
       " 'sentiency',\n",
       " 'setting',\n",
       " 'setting time',\n",
       " 'setting times',\n",
       " 'seuil critique',\n",
       " 'shapes pvc',\n",
       " 'shapes pvc inner',\n",
       " 'shear bond',\n",
       " 'shear bond bond strength',\n",
       " 'shear bond strength',\n",
       " 'shear induced',\n",
       " 'shear strength',\n",
       " 'shorter curing',\n",
       " 'show',\n",
       " 'show good',\n",
       " 'showed',\n",
       " 'shown',\n",
       " 'shrinkage',\n",
       " 'shrinking',\n",
       " 'shs joints axial',\n",
       " 'shs joints large',\n",
       " 'significant differences',\n",
       " 'significantly different',\n",
       " 'silica fume',\n",
       " 'similar',\n",
       " 'situ observation',\n",
       " 'solid body substance',\n",
       " 'solutions lithine',\n",
       " 'solutions zircaloy',\n",
       " 'sont',\n",
       " 'sort',\n",
       " 'sous vide',\n",
       " 'spatial property',\n",
       " 'spatiality',\n",
       " 'specimen geometry',\n",
       " 'specimen processed',\n",
       " 'specimen processed two',\n",
       " 'ssw reinforced',\n",
       " 'statistically analyzed',\n",
       " 'status',\n",
       " 'steel concrete',\n",
       " 'steel concrete concrete pvc',\n",
       " 'steel concrete pvc concrete pvc shs',\n",
       " 'steel tubes',\n",
       " 'straight line',\n",
       " 'strain combined',\n",
       " 'strain combined loading',\n",
       " 'strain component',\n",
       " 'strain controlled',\n",
       " 'strain hardening',\n",
       " 'strain path',\n",
       " 'strain rate',\n",
       " 'strain rate rate sensitivity',\n",
       " 'strain rate sensitivity',\n",
       " 'strain rates',\n",
       " 'strains obtained',\n",
       " 'strength concrete',\n",
       " 'strength development',\n",
       " 'strength insignificant',\n",
       " 'strength uts',\n",
       " 'strength values',\n",
       " 'strengthener',\n",
       " 'stress amplitude',\n",
       " 'stress fld',\n",
       " 'stress fld much',\n",
       " 'stress ratio',\n",
       " 'stress strain',\n",
       " 'strip nodes',\n",
       " 'strip shape',\n",
       " 'strong increase',\n",
       " 'strongly influenced',\n",
       " 'structural',\n",
       " 'structural behavior',\n",
       " 'structure could',\n",
       " 'studied',\n",
       " 'study performed',\n",
       " 'study two',\n",
       " 'stuff',\n",
       " 'substance',\n",
       " 'sudden transition',\n",
       " 'sufficiently high',\n",
       " 'suggest',\n",
       " 'suggests conduction',\n",
       " 'supercooled melts',\n",
       " 'superplasticizer',\n",
       " 'sur les',\n",
       " 'sur les faces',\n",
       " 'surfaces contact',\n",
       " 'symptom',\n",
       " 'system',\n",
       " 'takes place',\n",
       " 'taking account',\n",
       " 'technique applied',\n",
       " 'technique found',\n",
       " 'temperature',\n",
       " 'temperature dependence',\n",
       " 'temperature pulling',\n",
       " 'temperature pulling rate',\n",
       " 'temperature range',\n",
       " 'temperature regime',\n",
       " 'temperature rises',\n",
       " 'temperature therefore',\n",
       " 'temperature variation',\n",
       " 'temporary state',\n",
       " 'température',\n",
       " 'tensile properties',\n",
       " 'territorial division',\n",
       " 'test results',\n",
       " 'tested comparison',\n",
       " 'tetric ceram',\n",
       " 'theory',\n",
       " 'therefore',\n",
       " 'thermal expansion',\n",
       " 'thermal mechanical',\n",
       " 'thickness reduction',\n",
       " 'thickness reduction rate',\n",
       " 'thought',\n",
       " 'three dimensional',\n",
       " 'three kinds',\n",
       " 'three way',\n",
       " 'threshold temperature',\n",
       " 'thus obtained',\n",
       " 'thus reducing',\n",
       " 'time period',\n",
       " 'times lower',\n",
       " 'top surface',\n",
       " 'total porosity',\n",
       " 'tous les',\n",
       " 'tract',\n",
       " 'traditional',\n",
       " 'transition zone',\n",
       " 'transmission electron',\n",
       " 'transport current',\n",
       " 'trauma',\n",
       " 'tricalcium silicate',\n",
       " 'très',\n",
       " 'tube chord',\n",
       " 'tube chord member',\n",
       " 'two carbons',\n",
       " 'two different',\n",
       " 'two pass',\n",
       " 'two pass hybrid',\n",
       " 'two pass wire',\n",
       " 'ultimate limit',\n",
       " 'ultimate limit state',\n",
       " 'ultimate tensile',\n",
       " 'ultimate tensile strength',\n",
       " 'ultimate tensile tensile strength',\n",
       " 'ultrahigh vacuum',\n",
       " 'une corrosion',\n",
       " 'une corrosion très',\n",
       " 'une phase',\n",
       " 'unit',\n",
       " 'unpleasant person',\n",
       " 'upon',\n",
       " 'upper threshold',\n",
       " 'uranium hexafluoride',\n",
       " 'used',\n",
       " 'used develop',\n",
       " 'using ray',\n",
       " 'using theory',\n",
       " 'validated experimental',\n",
       " 'value obtained',\n",
       " 'variation conductivity',\n",
       " 'variety',\n",
       " 'vertical loss',\n",
       " 'vine',\n",
       " 'visible light curing',\n",
       " 'volume fraction',\n",
       " 'waste glass',\n",
       " 'water absorption',\n",
       " 'water cement',\n",
       " 'water content',\n",
       " 'water reactors',\n",
       " 'water sorption',\n",
       " 'way anova',\n",
       " 'wear rate',\n",
       " 'wear resistant',\n",
       " 'wear testing',\n",
       " 'well known',\n",
       " 'wet mix',\n",
       " 'wet mix dry',\n",
       " 'wet mix glass',\n",
       " 'whole',\n",
       " 'width ratio',\n",
       " 'width ratio hollow',\n",
       " 'wire drawing',\n",
       " 'wire drawing process',\n",
       " 'without superplasticizer',\n",
       " 'work roll',\n",
       " 'yield function',\n",
       " 'yield function chaboche',\n",
       " 'yield strength',\n",
       " 'yielded',\n",
       " 'yielded first',\n",
       " 'yielded first ultimate',\n",
       " 'yld yield',\n",
       " 'yld yield function',\n",
       " 'zircaloy',\n",
       " 'zircaloy samples',\n",
       " 'échantillons'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbeea7b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Compare against ontology\n",
    "import sys\n",
    "import re\n",
    "sys.path.append('../')\n",
    "from evaluation.ontology import sparql, walk\n",
    "from evaluation import ontology\n",
    "\n",
    "results =f\"\"\"\n",
    "\n",
    "            SELECT distinct ?id ?label ?comment WHERE {{\n",
    "                \n",
    "                OPTIONAL{{ ?id rdfs:label ?label . }}\n",
    "                #OPTIONAL{{ ?id rdfs:comment ?comment . }}\n",
    "            }}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "namespaces = \"\"\"\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    prefix owl: <http://www.w3.org/2002/07/owl#>\n",
    "    prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    prefix ns2: <http://www.w3.org/2006/time#>\n",
    "\"\"\"\n",
    "def separate_words(s):\n",
    "    # Use regex to split camelCase or PascalCase strings\n",
    "    words = re.sub('([a-z0-9])([A-Z])', r'\\1 \\2', s)\n",
    "    return words.lower()\n",
    "\n",
    "def _owl_get_classes(graph) -> list[tuple[str, str]]:\n",
    "    results = graph.query(\n",
    "        f\"\"\"\n",
    "            {namespaces}\n",
    "\n",
    "            SELECT distinct ?id ?label ?comment ?skoslabel WHERE {{\n",
    "                {{\n",
    "                    ?id a owl:Class .\n",
    "                    \n",
    "                }} UNION {{\n",
    "                    ?id a rdfs:Class .\n",
    "                }} UNION {{\n",
    "                    ?subclass rdfs:subClassOf ?id .\n",
    "                }} UNION {{\n",
    "                    ?id a owl:ObjectProperty .\n",
    "                }} UNION {{\n",
    "                    ?id a owl:DatatypeProperty .\n",
    "                }} UNION {{\n",
    "                    ?id a owl:NamedIndividual .\n",
    "                }}\n",
    "                OPTIONAL {{ \n",
    "                        ?id rdfs:label ?label . \n",
    "                        FILTER(LANG(?label) = \"en\")\n",
    "                    }}\n",
    "                OPTIONAL {{ \n",
    "                        ?id skos:prefLabel ?skoslabel . \n",
    "                        FILTER(LANG(?skoslabel) = \"en\")\n",
    "                    }}\n",
    "                FILTER (!isBlank(?id))\n",
    "            }}\n",
    "        \"\"\"\n",
    "    )\n",
    "    id_labels = []\n",
    "    for result in results:\n",
    "        if result.id and not result.label and not result.skoslabel:\n",
    "            id_labels.append(( result.id.toPython(), separate_words(result.id.toPython().split('#')[-1] if '#' in result.id.toPython() else result.id.toPython().split('/')[-1])))\n",
    "        elif result.label:\n",
    "            #id_labels.append((result.id.toPython(), result.label.value))\n",
    "            id_labels.append((separate_words(result.id.toPython().split('#')[-1] if '#' in result.id.toPython() else result.id.toPython().split('/')[-1]), ' '.join(re.findall('[A-Z][^A-Z]*', result.label.value)).lower()))\n",
    "        elif result.skoslabel:\n",
    "            id_labels.append((separate_words(result.id.toPython().split('#')[-1] if '#' in result.id.toPython() else result.id.toPython().split('/')[-1]), ' '.join(re.findall('[A-Z][^A-Z]*', result.skoslabel.value)).lower()))\n",
    "        elif result.comment:\n",
    "            id_labels.append((separate_words(result.id.toPython().split('#')[-1] if '#' in result.id.toPython() else result.id.toPython().split('/')[-1]), result.comment.value.lower()))\n",
    "    return id_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2e8b5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 53\n",
      "{'coordinate', 'microscopy', 'component_basis', 'z_axis_coordinate', 'second_axis_vector', 'family', 'axis_component', 'first_axis_component', 'burgers_vector', 'x_axis', 'magnitude', 'direction', 'lattice_plane', 'quantity_value', 'third_axis_vector', 'slip_plane_normal', 'third', 'axis_vector', 'first', 'second_axis_component', 'third_axis_component', 'y_axis', 'vector_magnitude', 'third_axis', 'vector', 'x_axis_coordinate', 'crystal', 'family_crystal', 'vector_component', 'first_axis_vector', 'lattice', 'defect', 'second', 'basis', 'vector_origin', 'coordinate_vector', 'position_vector', 'axis', 'y_axis_coordinate', 'quantity_kind', 'crystal_structure', 'vector_component_basis', 'second_axis', 'z_axis', 'slip_plane', 'first_axis', 'line_defect', 'position', 'plane', 'burgers', 'origin', 'kind', 'component'}\n"
     ]
    }
   ],
   "source": [
    "#g = ontology.sparql.graph_from(f'/home/ebrahim/ontology_evaluation/ontologies/PMDCO.ttl')\n",
    "#g = ontology.sparql.graph_from(f'/home/ebrahim/ontology_evaluation/ontologies/NanoMine.ttl') # NanoMine.ttl # enanomapper.owl # MaterialsMine.ttl\n",
    "g = ontology.sparql.graph_from(f'/home/ebrahim/ontology_evaluation/ontologies/DISO.ttl') # DISO.ttl # CHAMEO.ttl # CIF-core.ttl\n",
    "ontology_concepts_list = _owl_get_classes(g)\n",
    "words=3000\n",
    "ontology_concepts = set()\n",
    "for concept, i in ontology_concepts_list:\n",
    "    ontology_concepts.add(i)\n",
    "\n",
    "ontology_document = ' '.join([i.replace('_', ' ') for concept, i in ontology_concepts_list])\n",
    "#print(ontology_document)\n",
    "\n",
    "clean_text_o = preprocess_data(ontology_concepts)\n",
    "model_o, dictionary_o, doc_term_matrix_o = create_gensim_lsa_model(clean_text_o, 1, words, include_bigrams=True)\n",
    "\n",
    "# Extract unique words from the LSA model\n",
    "ontology_vocabulary = set()\n",
    "for i, _ in model_o.show_topics():\n",
    "    topic = model_o.show_topic(i, topn=len(ontology_concepts))\n",
    "    for word, score in topic:\n",
    "        ontology_vocabulary.add(word)\n",
    "print(\"length\", len(ontology_vocabulary))\n",
    "print(ontology_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93d794c4-3ec9-4998-bc1e-d4f69a78607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accounting',\n",
       " 'Acoustics and Ultrasonics',\n",
       " 'Aerospace Engineering',\n",
       " 'Aging',\n",
       " 'Agricultural and Biological Sciences (miscellaneous)',\n",
       " 'Agronomy and Crop Science',\n",
       " 'Analysis',\n",
       " 'Analytical Chemistry',\n",
       " 'Anatomy',\n",
       " 'Anesthesiology and Pain Medicine',\n",
       " 'Animal Science and Zoology',\n",
       " 'Anthropology',\n",
       " 'Applied Mathematics',\n",
       " 'Applied Microbiology and Biotechnology',\n",
       " 'Applied Psychology',\n",
       " 'Aquatic Science',\n",
       " 'Archeology',\n",
       " 'Architecture',\n",
       " 'Artificial Intelligence',\n",
       " 'Arts and Humanities (miscellaneous)',\n",
       " 'Astronomy and Astrophysics',\n",
       " 'Atmospheric Science',\n",
       " 'Atomic and Molecular Physics, and Optics',\n",
       " 'Automotive Engineering',\n",
       " 'Behavioral Neuroscience',\n",
       " 'Biochemistry',\n",
       " 'Biochemistry (medical)',\n",
       " 'Biochemistry, Genetics and Molecular Biology (miscellaneous)',\n",
       " 'Bioengineering',\n",
       " 'Biological Psychiatry',\n",
       " 'Biomaterials',\n",
       " 'Biomedical Engineering',\n",
       " 'Biophysics',\n",
       " 'Biotechnology',\n",
       " 'Building and Construction',\n",
       " 'Business and International Management',\n",
       " 'Cancer Research',\n",
       " 'Cardiology and Cardiovascular Medicine',\n",
       " 'Care Planning',\n",
       " 'Catalysis',\n",
       " 'Cell Biology',\n",
       " 'Cellular and Molecular Neuroscience',\n",
       " 'Ceramics and Composites',\n",
       " 'Chemical Engineering (miscellaneous)',\n",
       " 'Chemistry (miscellaneous)',\n",
       " 'Chiropractics',\n",
       " 'Civil and Structural Engineering',\n",
       " 'Clinical Biochemistry',\n",
       " 'Clinical Psychology',\n",
       " 'Cognitive Neuroscience',\n",
       " 'Colloid and Surface Chemistry',\n",
       " 'Communication',\n",
       " 'Complementary and Manual Therapy',\n",
       " 'Complementary and alternative medicine',\n",
       " 'Computational Mathematics',\n",
       " 'Computational Mechanics',\n",
       " 'Computational Theory and Mathematics',\n",
       " 'Computer Graphics and Computer-Aided Design',\n",
       " 'Computer Networks and Communications',\n",
       " 'Computer Science Applications',\n",
       " 'Computer Vision and Pattern Recognition',\n",
       " 'Computers in Earth Sciences',\n",
       " 'Condensed Matter Physics',\n",
       " 'Conservation',\n",
       " 'Control and Systems Engineering',\n",
       " 'Critical Care Nursing',\n",
       " 'Critical Care and Intensive Care Medicine',\n",
       " 'Dentistry (miscellaneous)',\n",
       " 'Dermatology',\n",
       " 'Development',\n",
       " 'Developmental Biology',\n",
       " 'Developmental Neuroscience',\n",
       " 'Developmental and Educational Psychology',\n",
       " 'Drug Discovery',\n",
       " 'Earth and Planetary Sciences (miscellaneous)',\n",
       " 'Earth-Surface Processes',\n",
       " 'Ecological Modeling',\n",
       " 'Ecology',\n",
       " 'Ecology, Evolution, Behavior and Systematics',\n",
       " 'Economic Geology',\n",
       " 'Economics and Econometrics',\n",
       " 'Education',\n",
       " 'Electrical and Electronic Engineering',\n",
       " 'Electrochemistry',\n",
       " 'Electronic, Optical and Magnetic Materials',\n",
       " 'Emergency Medicine',\n",
       " 'Emergency Nursing',\n",
       " 'Endocrine and Autonomic Systems',\n",
       " 'Endocrinology',\n",
       " 'Endocrinology, Diabetes and Metabolism',\n",
       " 'Energy (miscellaneous)',\n",
       " 'Energy Engineering and Power Technology',\n",
       " 'Engineering (miscellaneous)',\n",
       " 'Environmental Chemistry',\n",
       " 'Environmental Engineering',\n",
       " 'Epidemiology',\n",
       " 'Equine',\n",
       " 'Experimental and Cognitive Psychology',\n",
       " 'Family Practice',\n",
       " 'Filtration and Separation',\n",
       " 'Finance',\n",
       " 'Fluid Flow and Transfer Processes',\n",
       " 'Food Animals',\n",
       " 'Food Science',\n",
       " 'Forestry',\n",
       " 'Fuel Technology',\n",
       " 'Fundamentals and skills',\n",
       " 'Gastroenterology',\n",
       " 'General Agricultural and Biological Sciences',\n",
       " 'General Biochemistry, Genetics and Molecular Biology',\n",
       " 'General Business, Management and Accounting',\n",
       " 'General Chemical Engineering',\n",
       " 'General Chemistry',\n",
       " 'General Computer Science',\n",
       " 'General Dentistry',\n",
       " 'General Earth and Planetary Sciences',\n",
       " 'General Economics, Econometrics and Finance',\n",
       " 'General Energy',\n",
       " 'General Engineering',\n",
       " 'General Environmental Science',\n",
       " 'General Immunology and Microbiology',\n",
       " 'General Materials Science',\n",
       " 'General Mathematics',\n",
       " 'General Medicine',\n",
       " 'General Neuroscience',\n",
       " 'General Nursing',\n",
       " 'General Pharmacology, Toxicology and Pharmaceutics',\n",
       " 'General Physics and Astronomy',\n",
       " 'General Psychology',\n",
       " 'General Social Sciences',\n",
       " 'General Veterinary',\n",
       " 'Genetics',\n",
       " 'Genetics (clinical)',\n",
       " 'Geochemistry and Petrology',\n",
       " 'Geography, Planning and Development',\n",
       " 'Geology',\n",
       " 'Geophysics',\n",
       " 'Geotechnical Engineering and Engineering Geology',\n",
       " 'Geriatrics and Gerontology',\n",
       " 'Gerontology',\n",
       " 'Global and Planetary Change',\n",
       " 'Hardware and Architecture',\n",
       " 'Health (social science)',\n",
       " 'Health Informatics',\n",
       " 'Health Policy',\n",
       " 'Health, Toxicology and Mutagenesis',\n",
       " 'Hematology',\n",
       " 'Hepatology',\n",
       " 'Histology',\n",
       " 'History',\n",
       " 'History and Philosophy of Science',\n",
       " 'Horticulture',\n",
       " 'Human Factors and Ergonomics',\n",
       " 'Human-Computer Interaction',\n",
       " 'Immunology',\n",
       " 'Immunology and Allergy',\n",
       " 'Industrial and Manufacturing Engineering',\n",
       " 'Infectious Diseases',\n",
       " 'Information Systems',\n",
       " 'Information Systems and Management',\n",
       " 'Inorganic Chemistry',\n",
       " 'Insect Science',\n",
       " 'Instrumentation',\n",
       " 'Internal Medicine',\n",
       " 'Issues, ethics and legal aspects',\n",
       " 'LPN and LVN',\n",
       " 'Language and Linguistics',\n",
       " 'Law',\n",
       " 'Leadership and Management',\n",
       " 'Library and Information Sciences',\n",
       " 'Life-span and Life-course Studies',\n",
       " 'Linguistics and Language',\n",
       " 'Management Information Systems',\n",
       " 'Management Science and Operations Research',\n",
       " 'Management of Technology and Innovation',\n",
       " 'Management, Monitoring, Policy and Law',\n",
       " 'Marketing',\n",
       " 'Materials Chemistry',\n",
       " 'Materials Science (miscellaneous)',\n",
       " 'Maternity and Midwifery',\n",
       " 'Mechanical Engineering',\n",
       " 'Mechanics of Materials',\n",
       " 'Media Technology',\n",
       " 'Medical–Surgical Nursing',\n",
       " 'Medicine (miscellaneous)',\n",
       " 'Metals and Alloys',\n",
       " 'Microbiology',\n",
       " 'Microbiology (medical)',\n",
       " 'Modeling and Simulation',\n",
       " 'Molecular Biology',\n",
       " 'Molecular Medicine',\n",
       " 'Multidisciplinary',\n",
       " 'Nature and Landscape Conservation',\n",
       " 'Nephrology',\n",
       " 'Neurology',\n",
       " 'Neurology (clinical)',\n",
       " 'Neuropsychology and Physiological Psychology',\n",
       " 'Neuroscience (miscellaneous)',\n",
       " 'Nuclear Energy and Engineering',\n",
       " 'Nuclear and High Energy Physics',\n",
       " 'Numerical Analysis',\n",
       " 'Nutrition and Dietetics',\n",
       " 'Obstetrics and Gynecology',\n",
       " 'Occupational Therapy',\n",
       " 'Ocean Engineering',\n",
       " 'Oceanography',\n",
       " 'Oncology',\n",
       " 'Oncology (nursing)',\n",
       " 'Ophthalmology',\n",
       " 'Optometry',\n",
       " 'Oral Surgery',\n",
       " 'Organic Chemistry',\n",
       " 'Organizational Behavior and Human Resource Management',\n",
       " 'Orthodontics',\n",
       " 'Orthopedics and Sports Medicine',\n",
       " 'Otorhinolaryngology',\n",
       " 'Parasitology',\n",
       " 'Pathology and Forensic Medicine',\n",
       " 'Pediatrics, Perinatology and Child Health',\n",
       " 'Pharmaceutical Science',\n",
       " 'Pharmacology',\n",
       " 'Pharmacology (medical)',\n",
       " 'Pharmacology (nursing)',\n",
       " 'Pharmacy',\n",
       " 'Physical Therapy, Sports Therapy and Rehabilitation',\n",
       " 'Physical and Theoretical Chemistry',\n",
       " 'Physics and Astronomy (miscellaneous)',\n",
       " 'Physiology',\n",
       " 'Physiology (medical)',\n",
       " 'Plant Science',\n",
       " 'Pollution',\n",
       " 'Polymers and Plastics',\n",
       " 'Process Chemistry and Technology',\n",
       " 'Pshychiatric Mental Health',\n",
       " 'Psychiatry and Mental health',\n",
       " 'Public Administration',\n",
       " 'Public Health, Environmental and Occupational Health',\n",
       " 'Pulmonary and Respiratory Medicine',\n",
       " 'Radiation',\n",
       " 'Radiological and Ultrasound Technology',\n",
       " 'Radiology, Nuclear Medicine and imaging',\n",
       " 'Rehabilitation',\n",
       " 'Renewable Energy, Sustainability and the Environment',\n",
       " 'Reproductive Medicine',\n",
       " 'Research and Theory',\n",
       " 'Rheumatology',\n",
       " 'Safety Research',\n",
       " 'Safety, Risk, Reliability and Quality',\n",
       " 'Sensory Systems',\n",
       " 'Signal Processing',\n",
       " 'Small Animals',\n",
       " 'Social Psychology',\n",
       " 'Sociology and Political Science',\n",
       " 'Software',\n",
       " 'Soil Science',\n",
       " 'Space and Planetary Science',\n",
       " 'Spectroscopy',\n",
       " 'Speech and Hearing',\n",
       " 'Statistical and Nonlinear Physics',\n",
       " 'Statistics and Probability',\n",
       " 'Statistics, Probability and Uncertainty',\n",
       " 'Strategy and Management',\n",
       " 'Stratigraphy',\n",
       " 'Structural Biology',\n",
       " 'Surfaces and Interfaces',\n",
       " 'Surfaces, Coatings and Films',\n",
       " 'Surgery',\n",
       " 'Theoretical Computer Science',\n",
       " 'Toxicology',\n",
       " 'Transplantation',\n",
       " 'Transportation',\n",
       " 'Urology',\n",
       " 'Veterinary (miscellaneous)',\n",
       " 'Virology',\n",
       " 'Waste Management and Disposal',\n",
       " 'Water Science and Technology'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98254998",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# getting the domain papers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'  # Example model, replace with desired model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to compute embedding for a word\n",
    "def get_word_embedding(word):\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Extract embedding for the first token ([CLS] token)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Example target subject\n",
    "target_subject = 'Nanomaterials'#'Characterization'\n",
    "\n",
    "# Define threshold for confidence score\n",
    "threshold = 0.80  # Example threshold, adjust as needed\n",
    "\n",
    "# Compute aggregated embedding for the target subject\n",
    "target_embedding = np.mean([get_word_embedding(word) for word in target_subject.split()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "447df3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_embeddings = []\n",
    "for subject in list(set(all_topics)):\n",
    "    # Example code to compute similarity with each subject's embedding\n",
    "    subject_embeddings.append(np.mean([get_word_embedding(word) for word in subject.split()], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "348fe4f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Compute semantic similarity and confidence score for each subject\n",
    "mapped_subjects = []\n",
    "for i, subject_embedding in enumerate(subject_embeddings):\n",
    "    # Example code to compute similarity with each subject's embedding\n",
    "    similarity = np.dot(target_embedding, subject_embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(subject_embedding))\n",
    "    confidence_score = (similarity + 1) / 2  # Normalize to range [0, 1]\n",
    "    # Filter out mapped subjects based on threshold\n",
    "    if confidence_score >= threshold:\n",
    "        mapped_subjects.append((list(set(all_topics))[i], confidence_score))\n",
    "\n",
    "# Sort mapped subjects by confidence score (highest to lowest)\n",
    "mapped_subjects = sorted(mapped_subjects, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cded5598-64fc-438f-9d91-1e1cc712603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Biomaterials', 0.977644145488739),\n",
       " ('Electrochemistry', 0.8948090374469757),\n",
       " ('Bioengineering', 0.8838181793689728),\n",
       " ('General Pharmacology, Toxicology and Pharmaceutics', 0.8743786215782166),\n",
       " ('Optometry', 0.8731647729873657),\n",
       " ('Biophysics', 0.8728172183036804),\n",
       " ('Geochemistry and Petrology', 0.8646673560142517),\n",
       " ('Health, Toxicology and Mutagenesis', 0.8638242781162262),\n",
       " ('Acoustics and Ultrasonics', 0.8575528860092163),\n",
       " ('General Immunology and Microbiology', 0.8571594059467316),\n",
       " ('Pharmacology (nursing)', 0.85525843501091),\n",
       " ('Microbiology (medical)', 0.854907214641571),\n",
       " ('Geotechnical Engineering and Engineering Geology', 0.8539265990257263),\n",
       " ('Catalysis', 0.8514692187309265),\n",
       " ('Pharmacology (medical)', 0.8497039377689362),\n",
       " ('Applied Microbiology and Biotechnology', 0.8483344316482544),\n",
       " ('Spectroscopy', 0.8476815223693848),\n",
       " ('General Economics, Econometrics and Finance', 0.8465488255023956),\n",
       " ('Environmental Chemistry', 0.8461267650127411),\n",
       " ('Neurology (clinical)', 0.8460090756416321),\n",
       " ('Geophysics', 0.8454417288303375),\n",
       " ('Materials Chemistry', 0.8440684974193573),\n",
       " ('Immunology and Allergy', 0.8439373672008514),\n",
       " ('Inorganic Chemistry', 0.842900425195694),\n",
       " ('Endocrinology, Diabetes and Metabolism', 0.8427276909351349),\n",
       " ('Virology', 0.8426788747310638),\n",
       " ('Health Informatics', 0.8426186144351959),\n",
       " ('Ecology, Evolution, Behavior and Systematics', 0.8422470390796661),\n",
       " ('Biochemistry (medical)', 0.8422077298164368),\n",
       " ('Economics and Econometrics', 0.8419777452945709),\n",
       " ('Automotive Engineering', 0.8419696092605591),\n",
       " ('Environmental Engineering', 0.8413610756397247),\n",
       " ('Chemical Engineering (miscellaneous)', 0.8411079347133636),\n",
       " ('Analytical Chemistry', 0.8389559686183929),\n",
       " ('Radiology, Nuclear Medicine and imaging', 0.8386790454387665),\n",
       " ('Human-Computer Interaction', 0.8377406001091003),\n",
       " ('Biomedical Engineering', 0.837671548128128),\n",
       " ('Microbiology', 0.8372740745544434),\n",
       " ('Biotechnology', 0.836475670337677),\n",
       " ('Nutrition and Dietetics', 0.8362393975257874),\n",
       " ('Toxicology', 0.8359913229942322),\n",
       " ('Neuropsychology and Physiological Psychology', 0.8350300192832947),\n",
       " ('Endocrine and Autonomic Systems', 0.8349448144435883),\n",
       " ('Nephrology', 0.8345420062541962),\n",
       " ('Oceanography', 0.8342051804065704),\n",
       " ('Surfaces, Coatings and Films', 0.834026962518692),\n",
       " ('Astronomy and Astrophysics', 0.8327332437038422),\n",
       " ('Ceramics and Composites', 0.8326246440410614),\n",
       " ('Pediatrics, Perinatology and Child Health', 0.8324644565582275),\n",
       " ('Biochemistry', 0.8320799767971039),\n",
       " ('Chemistry (miscellaneous)', 0.8320772051811218),\n",
       " ('Geriatrics and Gerontology', 0.8320273458957672),\n",
       " ('Computer Science Applications', 0.8317933678627014),\n",
       " ('Hematology', 0.8317745923995972),\n",
       " ('Aerospace Engineering', 0.8312229216098785),\n",
       " ('Earth-Surface Processes', 0.8311509788036346),\n",
       " ('Mechanical Engineering', 0.831019252538681),\n",
       " ('Radiological and Ultrasound Technology', 0.8307918310165405),\n",
       " ('Human Factors and Ergonomics', 0.8301549553871155),\n",
       " ('Engineering (miscellaneous)', 0.8300914764404297),\n",
       " ('Obstetrics and Gynecology', 0.8300677239894867),\n",
       " ('Oncology (nursing)', 0.8298678994178772),\n",
       " ('Organic Chemistry', 0.8293933570384979),\n",
       " ('General Chemical Engineering', 0.8288731873035431),\n",
       " ('Anesthesiology and Pain Medicine', 0.8287434875965118),\n",
       " ('Physiology (medical)', 0.8286049067974091),\n",
       " ('Biochemistry, Genetics and Molecular Biology (miscellaneous)',\n",
       "  0.8283056318759918),\n",
       " ('Orthopedics and Sports Medicine', 0.8282627463340759),\n",
       " ('Computational Mechanics', 0.8282302021980286),\n",
       " ('Colloid and Surface Chemistry', 0.8275798857212067),\n",
       " ('Materials Science (miscellaneous)', 0.8271187245845795),\n",
       " ('Ocean Engineering', 0.8266630172729492),\n",
       " ('Electrical and Electronic Engineering', 0.8259955048561096),\n",
       " ('Neuroscience (miscellaneous)', 0.825921505689621),\n",
       " ('Endocrinology', 0.8256383240222931),\n",
       " ('Management, Monitoring, Policy and Law', 0.8253603279590607),\n",
       " ('Dentistry (miscellaneous)', 0.8249700665473938),\n",
       " ('Process Chemistry and Technology', 0.8247464597225189),\n",
       " ('Pharmaceutical Science', 0.824694812297821),\n",
       " ('Parasitology', 0.824528157711029),\n",
       " ('Electronic, Optical and Magnetic Materials', 0.8244816660881042),\n",
       " ('Polymers and Plastics', 0.8239638209342957),\n",
       " ('Economic Geology', 0.8235277533531189),\n",
       " ('Computer Graphics and Computer-Aided Design', 0.8231889605522156),\n",
       " ('General Chemistry', 0.8231513798236847),\n",
       " ('Agronomy and Crop Science', 0.823043704032898),\n",
       " ('Immunology', 0.8227450549602509),\n",
       " ('Physics and Astronomy (miscellaneous)', 0.8222756385803223),\n",
       " ('Computational Mathematics', 0.822219729423523),\n",
       " ('Pharmacology', 0.8222061693668365),\n",
       " ('Genetics (clinical)', 0.8220873475074768),\n",
       " ('General Business, Management and Accounting', 0.822002500295639),\n",
       " ('Industrial and Manufacturing Engineering', 0.8217402994632721),\n",
       " ('Architecture', 0.8205913305282593),\n",
       " ('Cardiology and Cardiovascular Medicine', 0.8203207850456238),\n",
       " ('General Biochemistry, Genetics and Molecular Biology', 0.8195215165615082),\n",
       " ('Soil Science', 0.8194887042045593),\n",
       " ('General Engineering', 0.8188965618610382),\n",
       " ('Clinical Biochemistry', 0.8176277577877045),\n",
       " ('Chiropractics', 0.8175609111785889),\n",
       " ('Mechanics of Materials', 0.8172832131385803),\n",
       " ('Geology', 0.816228985786438),\n",
       " ('Theoretical Computer Science', 0.8161516785621643),\n",
       " ('General Materials Science', 0.816131055355072),\n",
       " ('General Environmental Science', 0.8156139850616455),\n",
       " ('Physical and Theoretical Chemistry', 0.8155252635478973),\n",
       " ('Physical Therapy, Sports Therapy and Rehabilitation', 0.8153803050518036),\n",
       " ('Hardware and Architecture', 0.815028578042984),\n",
       " ('Applied Psychology', 0.8148411810398102),\n",
       " ('Maternity and Midwifery', 0.814465194940567),\n",
       " ('Energy Engineering and Power Technology', 0.8141689300537109),\n",
       " ('Anthropology', 0.8139839768409729),\n",
       " ('Ecology', 0.8138936758041382),\n",
       " ('Neurology', 0.8136628270149231),\n",
       " ('Computational Theory and Mathematics', 0.8135164380073547),\n",
       " ('Sociology and Political Science', 0.8133341670036316),\n",
       " ('Nuclear Energy and Engineering', 0.8132970631122589),\n",
       " ('General Physics and Astronomy', 0.812920093536377),\n",
       " ('Life-span and Life-course Studies', 0.8127406239509583),\n",
       " ('Media Technology', 0.8126322329044342),\n",
       " ('Fundamentals and skills', 0.812246710062027),\n",
       " ('Medicine (miscellaneous)', 0.812029093503952),\n",
       " ('Pathology and Forensic Medicine', 0.8119698464870453),\n",
       " ('Control and Systems Engineering', 0.8117429316043854),\n",
       " ('Applied Mathematics', 0.811475932598114),\n",
       " ('General Computer Science', 0.8114671111106873),\n",
       " ('Marketing', 0.8112416863441467),\n",
       " ('General Dentistry', 0.8110736310482025),\n",
       " ('Clinical Psychology', 0.8110158443450928),\n",
       " ('General Neuroscience', 0.8109009861946106),\n",
       " ('General Psychology', 0.8107941448688507),\n",
       " ('Physiology', 0.8104560375213623),\n",
       " ('Management Information Systems', 0.8104371130466461),\n",
       " ('Experimental and Cognitive Psychology', 0.8096812665462494),\n",
       " ('Veterinary (miscellaneous)', 0.8096198439598083),\n",
       " ('Cognitive Neuroscience', 0.8094724416732788),\n",
       " ('Gerontology', 0.8094678819179535),\n",
       " ('Agricultural and Biological Sciences (miscellaneous)', 0.8094030320644379),\n",
       " ('Communication', 0.8093690276145935),\n",
       " ('Nature and Landscape Conservation', 0.8093179762363434),\n",
       " ('Management of Technology and Innovation', 0.8092687726020813),\n",
       " ('Fuel Technology', 0.8092098534107208),\n",
       " ('Developmental Neuroscience', 0.8090701699256897),\n",
       " ('Accounting', 0.8088796138763428),\n",
       " ('Metals and Alloys', 0.8086462616920471),\n",
       " ('Social Psychology', 0.8085577487945557),\n",
       " ('Finance', 0.8078689277172089),\n",
       " ('Ecological Modeling', 0.8078590929508209),\n",
       " ('Statistical and Nonlinear Physics', 0.8077366054058075),\n",
       " ('Water Science and Technology', 0.8076858520507812),\n",
       " ('Atomic and Molecular Physics, and Optics', 0.8075436651706696),\n",
       " ('Computer Networks and Communications', 0.8072396516799927),\n",
       " ('Developmental Biology', 0.8069030940532684),\n",
       " ('Renewable Energy, Sustainability and the Environment', 0.8066012561321259),\n",
       " ('Statistics, Probability and Uncertainty', 0.8064537346363068),\n",
       " ('Civil and Structural Engineering', 0.8064090311527252),\n",
       " ('Statistics and Probability', 0.806004524230957),\n",
       " ('Linguistics and Language', 0.8059104681015015),\n",
       " ('Language and Linguistics', 0.8059104681015015),\n",
       " ('History and Philosophy of Science', 0.8056500852108002),\n",
       " ('Artificial Intelligence', 0.805294394493103),\n",
       " ('Information Systems and Management', 0.8049012720584869),\n",
       " ('Arts and Humanities (miscellaneous)', 0.8048864901065826),\n",
       " ('Anatomy', 0.8048636317253113),\n",
       " ('Plant Science', 0.8046720921993256),\n",
       " ('Molecular Biology', 0.8042840659618378),\n",
       " ('General Mathematics', 0.8040127754211426),\n",
       " ('Management Science and Operations Research', 0.8037370443344116),\n",
       " ('Structural Biology', 0.8036885559558868),\n",
       " ('Filtration and Separation', 0.8036231994628906),\n",
       " ('Computers in Earth Sciences', 0.8034021258354187),\n",
       " ('Histology', 0.8031696677207947),\n",
       " ('Radiation', 0.8028616607189178),\n",
       " ('Public Health, Environmental and Occupational Health', 0.8026134967803955),\n",
       " ('Business and International Management', 0.8024721443653107),\n",
       " ('Animal Science and Zoology', 0.8024627268314362),\n",
       " ('Molecular Medicine', 0.8021028935909271),\n",
       " ('Archeology', 0.8017773032188416),\n",
       " ('Geography, Planning and Development', 0.8016553521156311),\n",
       " ('Oncology', 0.8012853860855103),\n",
       " ('Biological Psychiatry', 0.801125705242157),\n",
       " ('Cell Biology', 0.8011228442192078),\n",
       " ('Strategy and Management', 0.8010286092758179),\n",
       " ('Earth and Planetary Sciences (miscellaneous)', 0.800601989030838),\n",
       " ('Nuclear and High Energy Physics', 0.800480842590332),\n",
       " ('Sensory Systems', 0.8003845810890198)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de4e5d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of papers in this domain 908\n"
     ]
    }
   ],
   "source": [
    "target_subject_abstracts, target_subject_titles = [], []\n",
    "# Print mapped subjects with confidence scores\n",
    "for mapped_subject, confidence_score in mapped_subjects[0:1]:\n",
    "    #print(f\"{mapped_subject}: {confidence_score}\")\n",
    "    target_abstracts, target_titles = papers_with_subject(document_list, titles, subjects, mapped_subject)\n",
    "    target_subject_abstracts.extend(target_abstracts)\n",
    "    target_subject_titles.extend(target_titles)\n",
    "    \n",
    "print('len of papers in this domain', len(target_subject_titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66e10f90-babe-4250-b9ca-9ed23fba04c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of papers in this domain 17821\n"
     ]
    }
   ],
   "source": [
    "target_subject_abstracts, target_subject_titles = [], []\n",
    "target_abstracts, target_titles = papers_with_subject(document_list, titles, subjects, 'General Materials Science') #'General Materials Science' # 'Mechanics of Materials'\n",
    "target_subject_abstracts.extend(target_abstracts)\n",
    "target_subject_titles.extend(target_titles)\n",
    "print('len of papers in this domain', len(target_subject_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ec5604d-203f-4552-8ba9-03d1e582f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "clean_text=preprocess_data(target_subject_abstracts)\n",
    "number_of_topics=20#len(clean_text)\n",
    "words=3000\n",
    "model, dictionary, doc_term_matrix =create_gensim_lsa_model(clean_text, number_of_topics,words)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "566a89f5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 8259\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "for i, _ in model.show_topics():\n",
    "    topic = model.show_topic(i, topn= 1000)\n",
    "    for word, score in topic:\n",
    "        unique_words.add(word)\n",
    "               \n",
    "print(f'number of unique words: {len(unique_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e95e82e8-78c2-4b03-b244-41f66991f6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words after WordNet expansion: 3014\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "unique_words_expanded = set()\n",
    "\n",
    "# add the reference books terms\n",
    "#with open('Reference Books/callister/1_terms.txt', \"r\", encoding=\"utf-8\") as file:\n",
    "with open('Reference Books/Askeland/3_terms.txt', \"r\", encoding=\"utf-8\") as file:\n",
    "    # Iterate through each line\n",
    "    for word in file:\n",
    "        word = word.strip()\n",
    "        unique_words.add(word)\n",
    "\n",
    "with open('Reference Books/callister/3_terms.txt', \"r\", encoding=\"utf-8\") as file:\n",
    "    # Iterate through each line\n",
    "    for word in file:\n",
    "        word = word.strip()\n",
    "        unique_words.add(word)\n",
    "    \n",
    "for word in unique_words:\n",
    "    # Check if the word has three or fewer characters\n",
    "    if len(word) <= 3:\n",
    "        continue\n",
    "    \n",
    "    # Check if the word contains a number using regular expressions\n",
    "    if re.search(r'\\d', word):\n",
    "        continue\n",
    "    \n",
    "    # Get WordNet hypernyms of one level\n",
    "    hierarchies = get_hierarchies(word.lower().replace('_', ' '), 1)\n",
    "    \n",
    "    if not hierarchies:\n",
    "        # No expansion, append word as it is\n",
    "        #unique_words_expanded.add(word.lower().replace('_', ' '))\n",
    "        continue\n",
    "        \n",
    "    # For every item in the hierarchy except the original\n",
    "    for hierarchy in hierarchies[:-1]:\n",
    "        for item in hierarchy:\n",
    "            for lemma_name in item.lemma_names():\n",
    "                word = lemma_name.lower().replace('_', ' ')\n",
    "                if len(word) <= 3:\n",
    "                    continue\n",
    "                \n",
    "                # Check if the word contains a number using regular expressions\n",
    "                if re.search(r'\\d', word):\n",
    "                    continue\n",
    "                unique_words_expanded.add(word)\n",
    "            #break\n",
    "        #break\n",
    "            \n",
    "                \n",
    "print(f'Number of unique words after WordNet expansion: {len(unique_words_expanded)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0878d0ba-857a-4b24-9dc1-db576f9ec9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'terminal',\n",
       " 'invariable',\n",
       " 'breakdown',\n",
       " 'defence reaction',\n",
       " 'solitaire',\n",
       " 'lineage',\n",
       " 'jumper cable',\n",
       " 'science lab',\n",
       " 'ratiocination',\n",
       " 'piece of land',\n",
       " 'body',\n",
       " 'convenience',\n",
       " 'continuance',\n",
       " 'world',\n",
       " 'gesture',\n",
       " 'theory',\n",
       " 'cadre',\n",
       " 'thawing',\n",
       " 'fluxion',\n",
       " 'substrate',\n",
       " 'equivalent',\n",
       " 'adult',\n",
       " 'legal philosophy',\n",
       " 'connectedness',\n",
       " 'uncovering',\n",
       " 'writing paper',\n",
       " 'decomposition',\n",
       " 'input',\n",
       " 'salmagundi',\n",
       " 'entree',\n",
       " 'cement',\n",
       " 'fig tree',\n",
       " \"potter's clay\",\n",
       " 'penny',\n",
       " 'harm',\n",
       " 'citrus',\n",
       " 'procedure',\n",
       " 'junction',\n",
       " 'electric outlet',\n",
       " 'deadbolt',\n",
       " 'inwardness',\n",
       " 'heading',\n",
       " 'cranny',\n",
       " 'deflection',\n",
       " 'electromagnetic wave',\n",
       " 'fencesitter',\n",
       " 'roentgen ray',\n",
       " 'strip',\n",
       " 'volume',\n",
       " 'rule',\n",
       " 'paint',\n",
       " 'neology',\n",
       " 'glassful',\n",
       " \"compositor's case\",\n",
       " 'alluviation',\n",
       " 'example',\n",
       " 'observation',\n",
       " 'ceremony',\n",
       " 'ash tree',\n",
       " 'high quality',\n",
       " 'exposure',\n",
       " 'promontory',\n",
       " \"man's clothing\",\n",
       " 'body substance',\n",
       " 'literary genre',\n",
       " 'mirror',\n",
       " 'sexual activity',\n",
       " 'wedlock',\n",
       " 'business line',\n",
       " 'ground',\n",
       " 'attendant',\n",
       " 'photo',\n",
       " 'mutation',\n",
       " 'prospect',\n",
       " 'motive',\n",
       " 'x-radiation',\n",
       " 'reflex action',\n",
       " 'simple closed curve',\n",
       " 'libyan islamic fighting group',\n",
       " 'sheep pen',\n",
       " 'stalk',\n",
       " 'metal',\n",
       " 'metallic',\n",
       " 'roadblock',\n",
       " 'feature',\n",
       " 'bitstock',\n",
       " 'res publica',\n",
       " 'case',\n",
       " 'disintegration',\n",
       " 'motility',\n",
       " 'effectuation',\n",
       " 'ingress',\n",
       " 'parliamentary procedure',\n",
       " 'fossil fuel',\n",
       " 'thermionic valve',\n",
       " 'personal relation',\n",
       " 'spirit',\n",
       " 'somatesthesia',\n",
       " 'personal relationship',\n",
       " 'discipline',\n",
       " 'light source',\n",
       " 'brass',\n",
       " 'chain of mountains',\n",
       " 'days',\n",
       " 'closing',\n",
       " 'verbal creation',\n",
       " 'fellow member',\n",
       " 'integer',\n",
       " 'exemplar',\n",
       " 'trauma',\n",
       " 'ascendancy',\n",
       " 'possible action',\n",
       " 'permit',\n",
       " 'caustic potash',\n",
       " 'external body part',\n",
       " 'track',\n",
       " 'punctuation',\n",
       " 'gynecologist',\n",
       " 'abolitionist',\n",
       " 'theoretical account',\n",
       " 'visual communication',\n",
       " 'speck',\n",
       " 'concave shape',\n",
       " 'passion',\n",
       " 'swimmer',\n",
       " 'status',\n",
       " 'outgrowth',\n",
       " 'flight feather',\n",
       " 'mental object',\n",
       " 'impression',\n",
       " 'help',\n",
       " 'strong suit',\n",
       " 'pavement',\n",
       " 'forepaw',\n",
       " 'make-up',\n",
       " 'abstraction',\n",
       " 'relevance',\n",
       " 'writ',\n",
       " 'variance',\n",
       " 'social structure',\n",
       " 'triple',\n",
       " 'generation',\n",
       " 'cognitive process',\n",
       " 'maximum',\n",
       " 'component',\n",
       " 'detail',\n",
       " 'conceptualization',\n",
       " 'affliction',\n",
       " 'history',\n",
       " 'proposition',\n",
       " 'harmonic',\n",
       " 'role model',\n",
       " 'hand',\n",
       " 'ramification',\n",
       " 'thermionic tube',\n",
       " 'well',\n",
       " 'state of matter',\n",
       " 'cognitive operation',\n",
       " 'decomposition reaction',\n",
       " 'printing process',\n",
       " 'base',\n",
       " 'story',\n",
       " 'coherence',\n",
       " 'fatigue',\n",
       " 'portmanteau word',\n",
       " 'personnel',\n",
       " 'fashion model',\n",
       " 'inclusion body',\n",
       " 'variable star',\n",
       " 'bed linen',\n",
       " 'amalgam',\n",
       " 'transparent gem',\n",
       " 'hostility',\n",
       " 'gait',\n",
       " 'kinship group',\n",
       " 'salutation',\n",
       " 'chief',\n",
       " 'loan',\n",
       " 'basketeer',\n",
       " 'hookup',\n",
       " 'dramatics',\n",
       " 'carrier',\n",
       " 'fundamental quantity',\n",
       " 'patch',\n",
       " 'concretism',\n",
       " 'dislocation',\n",
       " 'evolution',\n",
       " 'bond certificate',\n",
       " 'memorizer',\n",
       " 'nisus',\n",
       " 'linear measure',\n",
       " 'doings',\n",
       " 'interruption',\n",
       " 'wattage',\n",
       " 'chain',\n",
       " 'body process',\n",
       " 'dentine',\n",
       " 'cocain',\n",
       " 'predisposition',\n",
       " 'structure',\n",
       " 'duty',\n",
       " 'tangency',\n",
       " 'doorway',\n",
       " 'reasoning',\n",
       " 'conformity',\n",
       " 'counterbalance',\n",
       " 'noesis',\n",
       " 'specific',\n",
       " 'electrical circuit',\n",
       " 'command',\n",
       " 'photographic material',\n",
       " 'lower limit',\n",
       " 'neologism',\n",
       " 'reflection',\n",
       " 'rumination',\n",
       " 'nitty-gritty',\n",
       " 'dearie',\n",
       " 'periodical',\n",
       " 'supposal',\n",
       " 'difference of opinion',\n",
       " 'field glass',\n",
       " 'incursion',\n",
       " 'spread',\n",
       " 'push',\n",
       " 'positive identification',\n",
       " 'aliveness',\n",
       " 'circuit',\n",
       " 'itinerary',\n",
       " 'ligament',\n",
       " 'building',\n",
       " 'period of time',\n",
       " 'device',\n",
       " 'demeanour',\n",
       " 'noise',\n",
       " 'gallus',\n",
       " 'flight maneuver',\n",
       " 'reciprocity',\n",
       " 'law of nature',\n",
       " 'subject area',\n",
       " 'color property',\n",
       " 'radio beam',\n",
       " 'grammatical category',\n",
       " 'criminal offence',\n",
       " 'piping',\n",
       " 'refracting telescope',\n",
       " 'sex activity',\n",
       " 'drinking glass',\n",
       " 'demand',\n",
       " 'circumstances',\n",
       " 'user interface',\n",
       " 'actuation',\n",
       " 'assemblage',\n",
       " 'upper',\n",
       " 'conditions',\n",
       " 'ceremonial',\n",
       " 'home base',\n",
       " 'tube',\n",
       " 'factor iv',\n",
       " 'legal brief',\n",
       " 'airplane maneuver',\n",
       " 'mistake',\n",
       " 'component part',\n",
       " 'coming',\n",
       " 'computation',\n",
       " 'library paste',\n",
       " 'frequency',\n",
       " 'demarcation',\n",
       " 'tree',\n",
       " 'broker',\n",
       " 'ornamentation',\n",
       " 'jewel',\n",
       " 'edition',\n",
       " 'legal instrument',\n",
       " 'life',\n",
       " 'measuring',\n",
       " 'facial gesture',\n",
       " 'traveling',\n",
       " 'dae-han-min-gook',\n",
       " 'constant quantity',\n",
       " 'plus',\n",
       " 'formula',\n",
       " 'bodily structure',\n",
       " 'binder',\n",
       " 'beam of light',\n",
       " 'calibre',\n",
       " 'causa',\n",
       " 'laboratory',\n",
       " 'midpoint',\n",
       " 'license',\n",
       " 'tension',\n",
       " 'totality',\n",
       " 'belief',\n",
       " 'pentateuch',\n",
       " 'instability',\n",
       " 'orthodontic braces',\n",
       " 'chemical decomposition reaction',\n",
       " 'offer',\n",
       " 'thespian',\n",
       " 'interpretation',\n",
       " 'cast',\n",
       " 'steel',\n",
       " 'occurrent',\n",
       " 'plate',\n",
       " 'control',\n",
       " 'variation',\n",
       " 'cash',\n",
       " 'scheme',\n",
       " 'cloth',\n",
       " 'thickening',\n",
       " 'crystallisation',\n",
       " 'conductor',\n",
       " 'horizontal surface',\n",
       " 'charge account credit',\n",
       " 'melody',\n",
       " 'asset',\n",
       " 'golf-club',\n",
       " 'parting',\n",
       " 'dentin',\n",
       " 'law-breaking',\n",
       " 'clumsiness',\n",
       " 'cornerstone',\n",
       " 'meth',\n",
       " 'integration',\n",
       " 'conglutination',\n",
       " 'korean peninsula',\n",
       " 'trip',\n",
       " 'muzzle',\n",
       " 'refraction',\n",
       " 'research project',\n",
       " \"apothecaries' unit\",\n",
       " 'circumference',\n",
       " 'bottleful',\n",
       " 'sports equipment',\n",
       " 'competition',\n",
       " 'pinion',\n",
       " 'timing',\n",
       " 'first',\n",
       " 'cubicle',\n",
       " 'living thing',\n",
       " 'howitzer',\n",
       " 'furniture',\n",
       " 'makeup',\n",
       " 'thought process',\n",
       " 'deportment',\n",
       " 'alinement',\n",
       " 'essay',\n",
       " 'wrongdoer',\n",
       " 'papers',\n",
       " 'wage increase',\n",
       " 'involvement',\n",
       " 'divisor',\n",
       " 'treatment',\n",
       " 'soul',\n",
       " 'complex body part',\n",
       " 'resoluteness',\n",
       " 'environment',\n",
       " 'formation',\n",
       " 'emptiness',\n",
       " 'implement',\n",
       " 'unfortunate person',\n",
       " 'build',\n",
       " 'roughness',\n",
       " 'chemical',\n",
       " 'operation',\n",
       " 'disorderliness',\n",
       " 'light',\n",
       " 'beginning',\n",
       " 'ceremonial occasion',\n",
       " 'constituent',\n",
       " 'getting',\n",
       " 'blend',\n",
       " 'main course',\n",
       " 'writing',\n",
       " 'natural law',\n",
       " 'mark',\n",
       " 'firmness of purpose',\n",
       " 'strengthener',\n",
       " 'musical theme',\n",
       " 'donation',\n",
       " 'briny',\n",
       " 'resistance',\n",
       " 'province',\n",
       " 'stone',\n",
       " 'displacement unit',\n",
       " 'flake',\n",
       " 'usefulness',\n",
       " 'sense impression',\n",
       " 'sand',\n",
       " 'handbreadth',\n",
       " 'suburbia',\n",
       " 'magnetic declination',\n",
       " 'being',\n",
       " 'heat energy',\n",
       " 'filling',\n",
       " 'entry',\n",
       " 'sport',\n",
       " 'dosage',\n",
       " 'road',\n",
       " 'force per unit area',\n",
       " 'decoration',\n",
       " 'medicine',\n",
       " 'heart and soul',\n",
       " 'public exposure',\n",
       " 'police force',\n",
       " 'trail',\n",
       " 'curve ball',\n",
       " 'mishap',\n",
       " 'geographical region',\n",
       " 'libyan fighting group',\n",
       " 'spacing',\n",
       " 'phenomenon',\n",
       " 'raggedness',\n",
       " 'number one',\n",
       " 'wish',\n",
       " 'aggregate',\n",
       " 'garment',\n",
       " 'vitreous silica',\n",
       " 'conservativist',\n",
       " 'primary',\n",
       " 'commencement',\n",
       " 'agency',\n",
       " 'whole number',\n",
       " 'discourse',\n",
       " 'dimension',\n",
       " 'lede',\n",
       " 'adhesive material',\n",
       " 'territorial division',\n",
       " 'change of location',\n",
       " 'neighborhood',\n",
       " 'acquiring',\n",
       " 'piece of furniture',\n",
       " 'sum of money',\n",
       " 'chip',\n",
       " 'neural structure',\n",
       " 'situation',\n",
       " 'subject field',\n",
       " 'vista',\n",
       " 'taint',\n",
       " 'forward motion',\n",
       " 'dental amalgam',\n",
       " 'door',\n",
       " 'loading',\n",
       " 'argument',\n",
       " 'pathology',\n",
       " 'density',\n",
       " 'unpleasant person',\n",
       " 'human face',\n",
       " 'principal sum',\n",
       " 'social control',\n",
       " 'years',\n",
       " 'wall plug',\n",
       " 'sodium hydroxide',\n",
       " 'copiousness',\n",
       " 'facial expression',\n",
       " 'cellphone',\n",
       " 'radio frequency',\n",
       " 'signal',\n",
       " 'written matter',\n",
       " 'comportment',\n",
       " 'light unit',\n",
       " 'sealing material',\n",
       " 'parcel of land',\n",
       " 'article',\n",
       " 'adhesive',\n",
       " 'gathering',\n",
       " 'measurement',\n",
       " 'commonwealth',\n",
       " 'somatic sensation',\n",
       " 'socio-economic class',\n",
       " 'transition',\n",
       " 'cell',\n",
       " 'miscellany',\n",
       " 'strength',\n",
       " 'knowledge domain',\n",
       " 'musical notation',\n",
       " 'mend',\n",
       " 'renovation',\n",
       " 'angle',\n",
       " 'lupus erythematosus',\n",
       " 'chemical phenomenon',\n",
       " 'quartz',\n",
       " 'unconscious process',\n",
       " 'lechatelierite',\n",
       " 'plication',\n",
       " 'decrease',\n",
       " 'periodic event',\n",
       " 'the likes of',\n",
       " 'emphasis',\n",
       " 'zone',\n",
       " 'combine',\n",
       " 'normal',\n",
       " 'economic value',\n",
       " 'carbon dioxide',\n",
       " 'black lead',\n",
       " 'looking at',\n",
       " 'subject',\n",
       " 'cost',\n",
       " 'necessity',\n",
       " 'discovery',\n",
       " 'variable quantity',\n",
       " 'physiological reaction',\n",
       " 'high command',\n",
       " 'better',\n",
       " 'electron tube',\n",
       " 'mentation',\n",
       " 'deoxyephedrine',\n",
       " 'defense mechanism',\n",
       " 'initiation',\n",
       " 'molecule',\n",
       " 'mien',\n",
       " 'topic',\n",
       " 'touchstone',\n",
       " 'self-examination',\n",
       " 'musical mode',\n",
       " 'fund',\n",
       " 'shelter',\n",
       " 'activeness',\n",
       " 'snapper',\n",
       " 'field of study',\n",
       " 'somesthesia',\n",
       " 'drop-off',\n",
       " 'shift',\n",
       " 'scale leaf',\n",
       " 'last',\n",
       " 'contour',\n",
       " 'airplane',\n",
       " 'incorporation',\n",
       " 'inebriant',\n",
       " 'view',\n",
       " 'independent variable',\n",
       " 'judgment',\n",
       " 'line of business',\n",
       " 'cleft',\n",
       " 'inability',\n",
       " 'devolution',\n",
       " 'medication',\n",
       " 'tout ensemble',\n",
       " 'position',\n",
       " 'workplace',\n",
       " 'forum',\n",
       " 'methamphetamine',\n",
       " 'acquisition',\n",
       " 'tensity',\n",
       " 'social class',\n",
       " 'deracination',\n",
       " 'good',\n",
       " 'authorship',\n",
       " 'individualist',\n",
       " 'typeface',\n",
       " 'value',\n",
       " 'full term',\n",
       " 'measure',\n",
       " 'configuration',\n",
       " 'impediment',\n",
       " 'lamination',\n",
       " 'flora',\n",
       " 'iteration',\n",
       " 'equipoise',\n",
       " 'meeting place',\n",
       " 'precipitation',\n",
       " 'standard',\n",
       " 'planing machine',\n",
       " 'good health',\n",
       " 'wage hike',\n",
       " 'rubbing',\n",
       " 'tout',\n",
       " 'felony',\n",
       " 'discussion',\n",
       " 'inelegance',\n",
       " 'vacuum',\n",
       " 'explorer',\n",
       " 'handling',\n",
       " 'military position',\n",
       " 'cycles/second',\n",
       " 'artistic style',\n",
       " 'shape',\n",
       " 'wind',\n",
       " 'korea',\n",
       " 'jurisprudence',\n",
       " 'warmth',\n",
       " 'coin',\n",
       " 'growing',\n",
       " 'eccentric',\n",
       " 'sideslip',\n",
       " 'arena',\n",
       " 'enclosure',\n",
       " 'mathematical statement',\n",
       " 'roll',\n",
       " 'u.s.',\n",
       " 'formulation',\n",
       " 'small',\n",
       " 'theater',\n",
       " 'printing',\n",
       " 'language unit',\n",
       " 'screw',\n",
       " 'melioration',\n",
       " 'part',\n",
       " 'change',\n",
       " 'species',\n",
       " 'free energy',\n",
       " 'secant',\n",
       " 'violence',\n",
       " 'information',\n",
       " 'physical object',\n",
       " 'potash',\n",
       " 'glasswork',\n",
       " 'bailiwick',\n",
       " 'text',\n",
       " 'burden',\n",
       " 'obstructer',\n",
       " 'social group',\n",
       " 'alloy',\n",
       " 'guidance',\n",
       " 'place',\n",
       " 'cinder',\n",
       " 'matrix',\n",
       " 'filter',\n",
       " 'inborn reflex',\n",
       " 'body part',\n",
       " 'ensemble',\n",
       " 'contents',\n",
       " 'anchor ring',\n",
       " 'natural event',\n",
       " 'capital',\n",
       " 'headland',\n",
       " 'exhibition',\n",
       " 'solid',\n",
       " 'extremum',\n",
       " 'roast',\n",
       " 'flux',\n",
       " 'consequence',\n",
       " 'clinker',\n",
       " 'decorativeness',\n",
       " 'decline',\n",
       " 'mold',\n",
       " 'musical composition',\n",
       " 'border',\n",
       " 'radius',\n",
       " 'target',\n",
       " 'building material',\n",
       " 'outset',\n",
       " 'crease',\n",
       " 'watching',\n",
       " 'cube',\n",
       " 'foliage',\n",
       " 'businessman',\n",
       " 'proposal',\n",
       " 'compression',\n",
       " 'independent',\n",
       " 'casting',\n",
       " 'purchase order',\n",
       " 'animal group',\n",
       " 'abidance',\n",
       " 'tornado',\n",
       " 'carrying into action',\n",
       " 'sense datum',\n",
       " 'abstract thought',\n",
       " 'dancing',\n",
       " 'geezerhood',\n",
       " 'drink',\n",
       " 'body structure',\n",
       " 'causal factor',\n",
       " 'rail line',\n",
       " 'clew',\n",
       " 'dioxide',\n",
       " 'administrative division',\n",
       " 'pains',\n",
       " 'vigour',\n",
       " 'quill',\n",
       " 'pulley block',\n",
       " 'generalization',\n",
       " 'report',\n",
       " 'warrantee',\n",
       " 'surliness',\n",
       " 'pedigree',\n",
       " 'comment',\n",
       " 'columbiform bird',\n",
       " 'full point',\n",
       " 'terrorist group',\n",
       " 'phratry',\n",
       " 'heavy metal',\n",
       " 'motivation',\n",
       " 'holding',\n",
       " 'property',\n",
       " 'depression',\n",
       " 'somebody',\n",
       " 'mathematical function',\n",
       " 'beam',\n",
       " 'cubic content unit',\n",
       " 'reseda luteola',\n",
       " 'possible',\n",
       " 'spark advance',\n",
       " 'toughness',\n",
       " 'seasoning',\n",
       " 'boldness',\n",
       " 'best',\n",
       " 'consistency',\n",
       " 'reaper binder',\n",
       " 'business enterprise',\n",
       " 'racing shell',\n",
       " 'necessary',\n",
       " 'middleman',\n",
       " 'sheath',\n",
       " 'animal material',\n",
       " 'grade',\n",
       " 'abasement',\n",
       " 'intervention',\n",
       " 'boundary',\n",
       " 'system of measurement',\n",
       " 'solid state',\n",
       " 'rational motive',\n",
       " 'sensitivity',\n",
       " 'heaviness',\n",
       " 'higher-up',\n",
       " 'texture',\n",
       " 'adamant',\n",
       " 'gun muzzle',\n",
       " 'aspiration',\n",
       " 'crack cocaine',\n",
       " 'scissure',\n",
       " 'dross',\n",
       " 'sept',\n",
       " 'stiffness',\n",
       " 'calcedony',\n",
       " 'paper',\n",
       " 'point of accumulation',\n",
       " 'fluidness',\n",
       " 'head teacher',\n",
       " 'taxonomic group',\n",
       " 'finale',\n",
       " 'version',\n",
       " 'uniformness',\n",
       " 'written report',\n",
       " 'civil rights activist',\n",
       " 'review article',\n",
       " 'constitution',\n",
       " 'wrench',\n",
       " 'carrefour',\n",
       " 'biddy',\n",
       " 'disk',\n",
       " 'geographical area',\n",
       " 'pack',\n",
       " 'entryway',\n",
       " 'degeneration',\n",
       " 'textile',\n",
       " 'religious text',\n",
       " 'sexual union',\n",
       " 'controller',\n",
       " 'illness',\n",
       " 'unsuccessful person',\n",
       " 'cut of beef',\n",
       " 'optical instrument',\n",
       " 'enation',\n",
       " 'effectiveness',\n",
       " 'member',\n",
       " 'fixing',\n",
       " 'programme',\n",
       " 'trade protection',\n",
       " 'reason',\n",
       " 'facility',\n",
       " 'opportunity',\n",
       " 'bender',\n",
       " 'warp',\n",
       " 'regulation',\n",
       " 'platform',\n",
       " 'religious ceremony',\n",
       " 'chloride',\n",
       " 'collection',\n",
       " 'epithelial duct',\n",
       " 'quiver',\n",
       " 'suspender',\n",
       " 'goodness',\n",
       " 'signaling',\n",
       " 'braces',\n",
       " 'glasses',\n",
       " 'incurvature',\n",
       " 'marriage',\n",
       " 'graduated table',\n",
       " 'scalper',\n",
       " 'practice',\n",
       " 'histrion',\n",
       " 'event',\n",
       " 'consumption',\n",
       " 'electric power',\n",
       " 'adventurer',\n",
       " 'intellectual',\n",
       " 'layer',\n",
       " 'raise',\n",
       " 'quill feather',\n",
       " 'photographic paper',\n",
       " 'sheepcote',\n",
       " 'happening',\n",
       " 'closure',\n",
       " 'grille',\n",
       " 'artifact',\n",
       " 'failure',\n",
       " 'solidifying',\n",
       " 'physical property',\n",
       " 'liveliness',\n",
       " 'strengthening',\n",
       " 'clan',\n",
       " 'physical process',\n",
       " 'kinsperson',\n",
       " 'derivative',\n",
       " 'facet',\n",
       " 'cubic measure',\n",
       " 'rhythm',\n",
       " 'ficus carica',\n",
       " 'shrinking',\n",
       " 'listing',\n",
       " 'equation',\n",
       " 'proceeding',\n",
       " 'certificate',\n",
       " 'leaf',\n",
       " 'expansion',\n",
       " 'seeing',\n",
       " 'union',\n",
       " 'upshot',\n",
       " 'demo',\n",
       " 'modus operandi',\n",
       " 'greeting',\n",
       " 'stipulation',\n",
       " 'meaning',\n",
       " 'dissemination',\n",
       " 'someone',\n",
       " 'nerve',\n",
       " 'presentment',\n",
       " 'manikin',\n",
       " 'diminution',\n",
       " 'thanks',\n",
       " 'hydrated oxide',\n",
       " 'principal',\n",
       " 'direction',\n",
       " 'state of mind',\n",
       " 'manner',\n",
       " 'psychometric test',\n",
       " 'confidential information',\n",
       " 'coldness',\n",
       " 'betterment',\n",
       " 'pencil lead',\n",
       " 'reduction',\n",
       " 'fundament',\n",
       " 'harvester',\n",
       " 'info',\n",
       " 'error',\n",
       " 'scurf',\n",
       " 'coinage',\n",
       " 'picture',\n",
       " 'examen',\n",
       " 'paste',\n",
       " 'module',\n",
       " 'reflex',\n",
       " 'current',\n",
       " 'system',\n",
       " 'semblance',\n",
       " 'musicalness',\n",
       " 'determinative',\n",
       " 'exponent',\n",
       " 'player',\n",
       " 'drafting',\n",
       " 'sheet of paper',\n",
       " 'official document',\n",
       " 'premix',\n",
       " 'steadiness',\n",
       " 'evaluation',\n",
       " 'addition',\n",
       " 'creating from raw materials',\n",
       " 'thermionic vacuum tube',\n",
       " 'linguistic rule',\n",
       " 'philosophical doctrine',\n",
       " 'pitting',\n",
       " 'inception',\n",
       " 'thinness',\n",
       " 'conflict',\n",
       " 'sense experience',\n",
       " 'hungarian monetary unit',\n",
       " 'difference',\n",
       " 'prostration',\n",
       " 'restraint',\n",
       " 'conservativism',\n",
       " 'suit of clothes',\n",
       " 'disembodied spirit',\n",
       " 'hard cash',\n",
       " 'gain',\n",
       " 'habit',\n",
       " 'applied science',\n",
       " 'coterie',\n",
       " 'monetary standard',\n",
       " 'terminal point',\n",
       " 'plan of action',\n",
       " 'lawsuit',\n",
       " 'present',\n",
       " 'show',\n",
       " 'interval',\n",
       " 'capacity measure',\n",
       " 'kick',\n",
       " 'growth',\n",
       " 'supreme headquarters allied powers europe',\n",
       " 'picture taking',\n",
       " 'time interval',\n",
       " 'asking',\n",
       " 'order of magnitude',\n",
       " 'width',\n",
       " 'hull',\n",
       " 'x ray',\n",
       " 'circumstance',\n",
       " 'conception',\n",
       " 'connexion',\n",
       " 'religious order',\n",
       " 'validity',\n",
       " 'sound structure',\n",
       " 'specimen',\n",
       " 'mannequin',\n",
       " 'apparatus',\n",
       " 'supporting players',\n",
       " 'metallic element',\n",
       " 'mental strain',\n",
       " 'laminate',\n",
       " 'bodily function',\n",
       " 'personal manner',\n",
       " 'style',\n",
       " 'emotionality',\n",
       " 'study',\n",
       " 'rise',\n",
       " 'offender',\n",
       " 'pillow slip',\n",
       " 'breathing in',\n",
       " 'fault',\n",
       " 'esthesis',\n",
       " 'rules of order',\n",
       " 'logical thinking',\n",
       " 'introspection',\n",
       " 'trial',\n",
       " 'foodstuff',\n",
       " 'bone',\n",
       " 'public presentation',\n",
       " 'rock',\n",
       " 'knowledge base',\n",
       " 'stop',\n",
       " 'bourgeois',\n",
       " 'top dog',\n",
       " 'theatre',\n",
       " \"typesetter's case\",\n",
       " 'volume unit',\n",
       " 'star',\n",
       " 'written document',\n",
       " 'justification',\n",
       " 'weakness',\n",
       " 'conducting wire',\n",
       " 'taxon',\n",
       " 'alignment',\n",
       " 'shield',\n",
       " 'figure',\n",
       " 'feeling',\n",
       " 'stress',\n",
       " 'flexure',\n",
       " 'large indefinite amount',\n",
       " 'possibility',\n",
       " 'inner circle',\n",
       " 'numerical quantity',\n",
       " 'dramatic art',\n",
       " 'custom',\n",
       " 'learning',\n",
       " 'deal',\n",
       " 'endeavour',\n",
       " 'review',\n",
       " 'electrical outlet',\n",
       " 'motif',\n",
       " 'public knowledge',\n",
       " 'lumber',\n",
       " 'soma',\n",
       " 'postulation',\n",
       " 'combination',\n",
       " 'compass point',\n",
       " 'caliber',\n",
       " 'authorisation',\n",
       " 'human relationship',\n",
       " 'fineness',\n",
       " 'instant',\n",
       " 'tender',\n",
       " 'basketball player',\n",
       " 'coating',\n",
       " 'supposition',\n",
       " 'celluloid',\n",
       " 'tooth',\n",
       " 'clay',\n",
       " 'relative frequency',\n",
       " 'mixture',\n",
       " 'heat',\n",
       " 'geologic process',\n",
       " 'organic process',\n",
       " 'entertainment',\n",
       " 'looking',\n",
       " 'application',\n",
       " 'man of affairs',\n",
       " 'intersection point',\n",
       " 'exercise',\n",
       " 'product',\n",
       " 'pettishness',\n",
       " 'perception',\n",
       " ...}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f674fa81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "component\n",
      "first\n",
      "position\n",
      "direction\n",
      "kind\n",
      "family\n",
      "second\n",
      "magnitude\n",
      "lattice\n",
      "basis\n",
      "crystal\n",
      "origin\n",
      "plane\n",
      "defect\n",
      "true_positive=14, false_positive=39, true_negative=0, false_negative=3000\n",
      "precision (relevance): 0.2641509433962264, recall (coverage): 0.0046449900464499, F1: 0.009129442451907402\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0 # was in the ontology and in the corpus\n",
    "false_positive = 0 # was not in the ontology, but was in the corpus\n",
    "true_negative = 0  # always 0\n",
    "false_negative = 0 # was in the ontology, but was not in the corpus\n",
    "\n",
    "\n",
    "for corpus_word in unique_words_expanded:\n",
    "    if corpus_word in ontology_vocabulary:\n",
    "        # was in the ontology and in the corpus\n",
    "        true_positive += 1\n",
    "        print(corpus_word)\n",
    "    else:\n",
    "        # was not in the ontology, but was in the corpus\n",
    "        false_negative += 1\n",
    "    \n",
    "for ontology_term in ontology_vocabulary:\n",
    "    if ontology_term not in unique_words_expanded:\n",
    "        # was in the ontology, but was not in the corpus\n",
    "        false_positive += 1\n",
    "        \n",
    "print(f'{true_positive=}, {false_positive=}, {true_negative=}, {false_negative=}')\n",
    "precision = true_positive / (true_positive + false_positive) # fitness \n",
    "recall = true_positive / (true_positive + false_negative) # unneeded concepts\n",
    "\n",
    "print(f'precision (relevance): {precision}, recall (coverage): {recall}, F1: {2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fdfcfccc-0b6e-4368-b207-7e6bba3cf4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magnitude\n",
      "lattice\n",
      "microscopy\n",
      "crystal\n",
      "defect\n",
      "first\n",
      "direction\n",
      "basis\n",
      "crystal_structure\n",
      "component\n",
      "second\n",
      "plane\n",
      "true_positive=12, false_positive=41, true_negative=0, false_negative=8407\n",
      "precision (relevance): 0.22641509433962265, recall (coverage): 0.0014253474284356812, F1: 0.0028328611898017\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0 # was in the ontology and in the corpus\n",
    "false_positive = 0 # was not in the ontology, but was in the corpus\n",
    "true_negative = 0  # always 0\n",
    "false_negative = 0 # was in the ontology, but was not in the corpus\n",
    "\n",
    "\n",
    "for corpus_word in unique_words:\n",
    "    if corpus_word in ontology_vocabulary:\n",
    "        # was in the ontology and in the corpus\n",
    "        true_positive += 1\n",
    "        print(corpus_word)\n",
    "    else:\n",
    "        # was not in the ontology, but was in the corpus\n",
    "        false_negative += 1\n",
    "    \n",
    "for ontology_term in ontology_vocabulary:\n",
    "    if ontology_term not in unique_words:\n",
    "        # was in the ontology, but was not in the corpus\n",
    "        false_positive += 1\n",
    "        \n",
    "print(f'{true_positive=}, {false_positive=}, {true_negative=}, {false_negative=}')\n",
    "precision = true_positive / (true_positive + false_positive) # fitness \n",
    "recall = true_positive / (true_positive + false_negative) # unneeded concepts\n",
    "\n",
    "print(f'precision (relevance): {precision}, recall (coverage): {recall}, F1: {2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845175b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ontology_files = os.listdir('/home/ebrahim/ontology_evaluation/ontologies/')\n",
    "results = []\n",
    "\n",
    "# Loop through each ontology file\n",
    "for ontology_file in ontology_files:\n",
    "    try:\n",
    "        ontology_concepts_list = _owl_get_classes(ontology.sparql.graph_from(f'/home/ebrahim/ontology_evaluation/ontologies/{ontology_file}'))\n",
    "\n",
    "        ontology_concepts = set()\n",
    "        for concept, i in ontology_concepts_list:\n",
    "            ontology_concepts.add(i)\n",
    "        \n",
    "        ontology_document = ' '.join([i.replace('_', ' ') for concept, i in ontology_concepts_list])\n",
    "        print(ontology_file)\n",
    "        # retrieve subject and then only related abstracts\n",
    "        target_subject = ontology_document#'crystalline materials'\n",
    "\n",
    "        # Define threshold for confidence score\n",
    "        threshold = 0.95  # Example threshold, adjust as needed\n",
    "\n",
    "        # Compute aggregated embedding for the target subject\n",
    "        target_embedding = np.mean([get_word_embedding(word) for word in target_subject.split()], axis=0)\n",
    "\n",
    "        # Compute semantic similarity and confidence score for each subject\n",
    "        mapped_subjects = []\n",
    "        for i, subject_embedding in enumerate(subject_embeddings):\n",
    "            # Example code to compute similarity with each subject's embedding\n",
    "            similarity = np.dot(target_embedding, subject_embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(subject_embedding))\n",
    "            confidence_score = (similarity + 1) / 2  # Normalize to range [0, 1]\n",
    "            # Filter out mapped subjects based on threshold\n",
    "            if confidence_score >= threshold:\n",
    "                mapped_subjects.append((list(set(all_topics))[i], confidence_score))\n",
    "\n",
    "        # Sort mapped subjects by confidence score (highest to lowest)\n",
    "        mapped_subjects = sorted(mapped_subjects, key=lambda x: x[1], reverse=True)\n",
    "        target_subject_abstracts, target_subject_titles = [], []\n",
    "        # Print mapped subjects with confidence scores\n",
    "        for mapped_subject, confidence_score in mapped_subjects:\n",
    "            #print(f\"{mapped_subject}: {confidence_score}\")\n",
    "            target_abstracts, target_titles = papers_with_subject(document_list, titles, subjects, mapped_subject)\n",
    "            target_subject_abstracts.extend(target_abstracts)\n",
    "            target_subject_titles.extend(target_titles)\n",
    "            \n",
    "        print('len of papers in this domain', len(target_subject_titles))\n",
    "        clean_text=preprocess_data(target_subject_abstracts)\n",
    "        number_of_topics=100#len(clean_text)\n",
    "        words=3000\n",
    "        model, dictionary, doc_term_matrix =create_gensim_lsa_model(clean_text, number_of_topics,words)\n",
    "        print('Done')\n",
    "\n",
    "        unique_words = set()\n",
    "        for i, _ in model.show_topics():\n",
    "            topic = model.show_topic(i, topn= 10)\n",
    "            for word, score in topic:\n",
    "                unique_words.add(word)\n",
    "                    \n",
    "        print(f'number of unique words: {len(unique_words)}')\n",
    "        clean_text_o = preprocess_data(ontology_concepts)\n",
    "        \n",
    "        model_o, dictionary_o, doc_term_matrix_o = create_gensim_lsa_model(clean_text_o, 1, words, include_bigrams=True)\n",
    "\n",
    "        ontology_vocabulary = set()\n",
    "        for i, _ in model_o.show_topics():\n",
    "            topic = model_o.show_topic(i, topn=len(ontology_concepts))\n",
    "            for word, score in topic:\n",
    "                ontology_vocabulary.add(word)\n",
    "        \n",
    "        print('ontology vocab')\n",
    "        print(ontology_vocabulary)\n",
    "        # Initialize evaluation metrics\n",
    "        true_positive = 0\n",
    "        false_positive = 0\n",
    "        true_negative = 0\n",
    "        false_negative = 0\n",
    "        print('unique_words vocab')\n",
    "        print(unique_words)\n",
    "        \n",
    "        # Calculate True Positive and False Positive\n",
    "        for corpus_word in unique_words:\n",
    "            if corpus_word in ontology_vocabulary:\n",
    "                true_positive += 1\n",
    "                #print(corpus_word)\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        \n",
    "        # Calculate False Negative\n",
    "        for ontology_term in ontology_vocabulary:\n",
    "            if ontology_term not in unique_words:\n",
    "                false_positive += 1\n",
    "        \n",
    "        # Calculate Precision and Recall\n",
    "        if (true_positive + false_positive) > 0:\n",
    "            precision = true_positive / (true_positive + false_positive)\n",
    "        else:\n",
    "            precision = 0.0  # or 'undefined' or any other value you'd like to assign\n",
    "\n",
    "        if (true_positive + false_negative) > 0:\n",
    "            recall = true_positive / (true_positive + false_negative)\n",
    "        else:\n",
    "            recall = 0.0  # or 'undefined' or any other value you'd like to assign\n",
    "        \n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Ontology': ontology_file,\n",
    "            'Number of concepts': len(ontology_vocabulary),\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'Accuracy': (true_positive)  / (true_positive + false_positive + false_negative)\n",
    "        })\n",
    "    except:\n",
    "        print('there is an error for', ontology_file)\n",
    "    \n",
    "# Print the table of results\n",
    "print(f\"{'Ontology':<30} {'Number of concepts':<30} {'Precision (Relevance)':<30} {'Recall (Coverage)':<30} {'Accuracy':<30}\")\n",
    "print(\"=\"*130)\n",
    "for result in results:\n",
    "    print(f\"{result['Ontology']:<30} {result['Number of concepts']:<30} {result['Precision']:<30.4f} {result['Recall']:<30.4f} {result['Accuracy']:<30.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_path = \"coverage_recall_lsa.csv\"\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Ontology', 'Number of concepts', 'Precision (Relevance)', 'Recall (Coverage)', 'F1-Measure', 'Accuracy']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow({\n",
    "            'Ontology': result['Ontology'],\n",
    "            'Number of concepts': result['Number of concepts'],\n",
    "            'Precision (Relevance)': \"{:.4f}\".format(result['Precision']),\n",
    "            'Recall (Coverage)': \"{:.4f}\".format(result['Recall']),\n",
    "            'F1-Measure': result['F1'],\n",
    "            'Accuracy': result['Accuracy']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525a43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
